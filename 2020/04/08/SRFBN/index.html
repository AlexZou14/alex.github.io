<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="description" content="Feedback Network for Image Super-Resolution论文阅读笔记"><meta name="keywords" content="深度学习,笔记,超分辨率"><meta name="author" content="秩同道合"><meta name="copyright" content="秩同道合"><meta name="theme-color" content="#0078E7"><title>Feedback Network for Image Super-Resolution论文阅读笔记 | 秩同道合的小站</title><link rel="shortcut icon" href="https://cdn.jsdelivr.net/gh/AlexZou14/CDN/img/favicon.ico"><link rel="preload" href="/css/hexo-theme-yun.css" as="style"><link rel="preload" href="/js/utils.js" as="script"><link rel="preload" href="/js/hexo-theme-yun.js" as="script"><link rel="prefetch" href="/js/sidebar.js" as="script"><link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin><link rel="stylesheet" href="/css/hexo-theme-yun.css"><link rel="alternate" href="/atom.xml" title="秩同道合的小站"><script id="yun-config">
    let Yun = window.Yun || {};
    let CONFIG = {"root":"/","title":"秩同道合的小站","version":"0.3.1","anonymous_image":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/avatar/none.jpg","say":{"api":"https://v1.hitokoto.cn","hitokoto":true},"valine":{"el":"#valine-container","verify":false,"notify":false,"appId":"eCgP91hRSX8OtvCIR4MgLfcl-gzGzoHsz","appKey":"N5gVT8kUx5O0wMvc47SU040Y","serverURLs":null,"placeholder":"大佬求指教&nbsp_(:з」∠)_ （填写邮箱可以收到回复通知～）","avatar":null,"meta":["nick","mail","link"],"pageSize":10,"lang":"zh-cn","visitor":true},"fireworks":{"colors":["102, 167, 221","62, 131, 225","33, 78, 194"]}};
  </script><script src="//at.alicdn.com/t/font_1140697_pa6cswvjpq.js" async></script><meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="秩同道合的小站" type="application/atom+xml">
</head><body><script defer src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script defer src="/js/ui/fireworks.js"></script><canvas class="fireworks"></canvas><div class="container"><a class="sidebar-toggle sidebar-toggle-fixed hty-icon-button"><div class="hamburger hamburger--spin" type="button"><span class="hamburger-box"><span class="hamburger-inner"></span></span></div></a><aside class="sidebar"><ul class="sidebar-nav"><li class="sidebar-nav-item sidebar-nav-toc sidebar-nav-active hty-icon-button" data-target="post-toc-wrap" title="文章目录"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-list-ordered"></use></svg></li><li class="sidebar-nav-item sidebar-nav-overview hty-icon-button" data-target="site-overview-wrap" title="站点概览"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-passport-line"></use></svg></li></ul><div class="sidebar-panel" id="site-overview-wrap"><div class="site-info fix-top"><a class="site-author-avatar" href="/about" title="秩同道合"><img loading="lazy" src="https://cdn.jsdelivr.net/gh/AlexZou14/CDN/img/touxiang.jpg" alt="秩同道合"></a><div class="site-author-name"><a href="/about">秩同道合</a></div><a class="site-name" href="/about/site.html">秩同道合的小站</a><sub class="site-subtitle">寻找志趣相投的伙伴！</sub><div class="site-desciption">我和你，以及我们的秩相同所以我们才等价！</div></div><nav class="site-state"><a class="site-state-item hty-icon-button icon-home" href="/" title="首页"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-home-4-line"></use></svg></span></a><div class="site-state-item site-state-posts"><a href="/archives" title="归档"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-archive-line"></use></svg></span><span class="site-state-item-count">11</span></a></div><div class="site-state-item site-state-categories"><a href="/categories" title="分类"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-2-line"></use></svg></span><span class="site-state-item-count">1</span></a></div><div class="site-state-item site-state-tags"><a href="/tags" title="标签"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="site-state-item-count">3</span></a></div><a class="site-state-item hty-icon-button" href="https://github.com/AlexZou14" target="_blank" rel="noopener" title="reward.comment"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-hand-coin-line"></use></svg></span></a></nav><hr style="margin-bottom:0.5rem"><div class="links-of-author"><a class="links-of-author-item hty-icon-button" rel="noopener" href="/atom.xml" title="RSS" target="_blank" style="color:orange"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-rss-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://github.com/AlexZou14" title="GitHub" target="_blank" style="color:#181717"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-github-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="mailto:1120375574@qq.com" title="E-Mail" target="_blank" style="color:#8E71C1"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-mail-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://space.bilibili.com/19164044" title="哔哩哔哩" target="_blank" style="color:#FF8EB3"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-bilibili-line"></use></svg></a></div><hr style="margin:0.5rem 1rem"><div class="links"><a class="links-item hty-icon-button" href="http://sotavision.cn" target="_blank" rel="noopener" title="工作组" style="color:#000000"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-send-plane-2-line"></use></svg></a></div></div><script defer src="/js/sidebar.js"></script><div class="sidebar-panel sidebar-panel-active" id="post-toc-wrap"><div class="post-toc"><div class="post-toc-progress"><div class="progress-bar"></div><div class="progress-info"><span class="progress-notice">您已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span></div></div><div class="post-toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#Abstract"><span class="toc-number">1.</span> <span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Introduction"><span class="toc-number">2.</span> <span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Related-work"><span class="toc-number">3.</span> <span class="toc-text">Related work</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Deep-learning-based-image-super-resolution"><span class="toc-number">3.1.</span> <span class="toc-text">Deep learning based image super-resolution</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Feedback-mechanism"><span class="toc-number">3.2.</span> <span class="toc-text">Feedback mechanism</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Curriculum-learning"><span class="toc-number">3.3.</span> <span class="toc-text">Curriculum learning</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Proposed-Method"><span class="toc-number">4.</span> <span class="toc-text">Proposed Method</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Network-structure"><span class="toc-number">4.1.</span> <span class="toc-text">Network structure</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Feedback-block"><span class="toc-number">4.2.</span> <span class="toc-text">Feedback block</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Loss-function"><span class="toc-number">4.3.</span> <span class="toc-text">Loss function</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Curriculum-learning-strategy"><span class="toc-number">4.4.</span> <span class="toc-text">Curriculum learning strategy</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Experiment"><span class="toc-number">5.</span> <span class="toc-text">Experiment</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Experiments-Details"><span class="toc-number">5.1.</span> <span class="toc-text">Experiments Details</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Network-analysis"><span class="toc-number">5.2.</span> <span class="toc-text">Network analysis</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Comparisons-with-state-of-the-arts"><span class="toc-number">5.3.</span> <span class="toc-text">Comparisons with state-of-the-arts</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Results-with-BI-degradation-model"><span class="toc-number">5.4.</span> <span class="toc-text">Results with BI degradation model</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Results-with-BD-and-DN-degradation-models"><span class="toc-number">5.5.</span> <span class="toc-text">Results with BD and DN degradation models</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Conclusions"><span class="toc-number">6.</span> <span class="toc-text">Conclusions</span></a></li></ol></div></div></div></aside><main class="sidebar-translate" id="content"><div id="post"><article class="post-block" itemscope itemtype="http://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://alexzou14.github.io/2020/04/08/SRFBN/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="秩同道合"><meta itemprop="description" content="Feedback Network for Image Super-Resolution论文阅读笔记"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="秩同道合的小站"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">Feedback Network for Image Super-Resolution论文阅读笔记</h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-calendar-line"></use></svg></span> <time title="创建时间：2020-04-08 11:19:33" itemprop="dateCreated datePublished" datetime="2020-04-08T11:19:33+08:00">2020-04-08</time></span><div class="post-count"><span class="post-symbolcount"><span class="post-meta-item-icon" title="本文字数"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-file-word-line"></use></svg></span> <span title="本文字数">6.8k</span><span class="post-meta-divider">-</span><span class="post-meta-item-icon" title="阅读时长"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-timer-line"></use></svg></span> <span title="阅读时长">14 分钟</span></span></div><span class="leancloud_visitors" id="/2020/04/08/SRFBN/" data-flag-title="Feedback Network for Image Super-Resolution论文阅读笔记"><span class="post-meta-item-icon" title="阅读次数"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-eye-line"></use></svg> <span class="leancloud-visitors-count"></span></span></span><div class="post-classify"><span class="post-category"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-line"></use></svg></span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a class="category" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="text">论文笔记</span></a></span></span><span class="post-tag"><span class="post-meta-divider">-</span><a class="tag" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">深度学习</span></a><a class="tag" href="/tags/%E7%AC%94%E8%AE%B0/"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">笔记</span></a><a class="tag" href="/tags/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87/"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">超分辨率</span></a></span></div></div></header><section class="post-body" itemprop="articleBody"><div class="post-content post-markdown"><h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>由于现有的基于深度学习的图像SR方法尚未充分利用人类视觉系统中常见的反馈机制，所以本文基于这一想法提出了一个图像超分辨率反馈网络(SRFBN)通过高层信息来细化低层信息。具体这种反馈机制，是用具有约束的RNN中的隐状态来实现这种反馈机制。这种反馈机制能够产生非常强的高层表征能力。。此外，作者还引入了curriculum learning 策略，使网络非常适合于更复杂的任务。</p>
<hr>
<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>随着网络的深度增加，参数的数量也会增加。大容量网络将占用大量存储资源并遭受过度拟合问题。为了减少网络参数，通常采用循环结构。因为具有重复结构的这些网络可以以前馈方式共享信息。但是，前馈方式使得先前的层不可能从以下层访问有用信息，即使采用跳过连接也是如此。<br>在本文中，作者提出了一种新的图像SR网络，即超分辨率反馈网络（SRFBN），以便通过反馈连接使用高级信息来改进低级信息。 所提出的SRFBN本质上是具有反馈块（FB）的RNN，其专门用于图像SR任务。<br>总之，我们的主要贡献如下：</p>
<ul>
<li>提出采用反馈机制的图像超分辨率反馈网络（SRFBN）。 通过反馈连接在自上而下的反馈流中提供高级信息。 同时，这种具有反馈连接的循环结构提供了强大的早期重建能力，并且仅需要很少的参数。</li>
<li>提出反馈块（FB），它不仅可以有效地处理反馈信息流，还可以通过上采样层和下采样层以及密集跳过连接来丰富高级表示。</li>
<li>为SRFBN提出curriculum -based训练策略，其中将具有增加的重建难度的HR图像作为连续迭代的目标馈入网络。 该策略使网络能够逐步学习复杂的退化模型，而对于那些只有一步预测的方法，同样的策略是不可能的。</li>
</ul>
<hr>
<h3 id="Related-work"><a href="#Related-work" class="headerlink" title="Related work"></a>Related work</h3><h4 id="Deep-learning-based-image-super-resolution"><a href="#Deep-learning-based-image-super-resolution" class="headerlink" title="Deep learning based image super-resolution"></a>Deep learning based image super-resolution</h4><p>这一部分作者主要回顾了深度学习在超分变率领域的应用和方法回顾。从2015年董超提出SRCN开始将深度学习引入超分辨领域，近几年的超分领域的不断发展，提出了很多方法，如：VDSR，EDSR等</p>
<h4 id="Feedback-mechanism"><a href="#Feedback-mechanism" class="headerlink" title="Feedback mechanism"></a>Feedback mechanism</h4><p>反馈机制能够允许该网络携带当前的输出去纠正之前的一些状态。<br>针对图片超分辨率中的feedback mechanism，有两个必要条件：<br>1）迭代 ；见下图(b)<br>2）重新路由（rerouting）系统的输出，以纠正（correct）每个循环中的输入， 在本文提出的网络结构中，实施feedback mechanism，有三个必不可少的部分:<br>1）在每一次迭代过程中都绑定loss；<br>2）使用循环结构（实现迭代的过程）；<br>3）在每一次迭代过程中提供低分辨率图片的输入。<br>上面三个部分缺一不可。</p>
<blockquote>
<p><img src="http://sotavision.cn/showdoc/server/../Public/Uploads/2020-03-11/5e68efd37e4e0.png" alt="" loading="lazy"></p>
</blockquote>
<h4 id="Curriculum-learning"><a href="#Curriculum-learning" class="headerlink" title="Curriculum learning"></a>Curriculum learning</h4><p>Curriculum learning逐渐增加了学习目标的难度，众所周知，这是改进训练程序的有效策略。早期的课程学习工作主要集中在一项任务上。 Pentina等以连续的方式将课程学习扩展到多个任务。虽然之前的工作主要集中在单个degradation过程，但我们对案例强制执行curriculum ，其中LR图像被多种类型的劣化所破坏。包含易于做出决策的curriculum可以针对一个问题进行解决，以逐步恢复损坏的LR图像。</p>
<hr>
<h3 id="Proposed-Method"><a href="#Proposed-Method" class="headerlink" title="Proposed Method"></a>Proposed Method</h3><blockquote>
<p><img src="http://sotavision.cn/showdoc/server/../Public/Uploads/2020-03-11/5e68f4db2d8fc.png" alt="" loading="lazy"></p>
</blockquote>
<p>见图我们提出的SRFBN可以被展开为T个迭代，迭代的顺序是从1到t，为了使得中间的状态能够携带一些输出信息，我们在每一次的迭代后面都会绑定一个loss值。<br>网络结构被分为三个模块：LR特征提取模块，反馈模块，重建模块</p>
<h4 id="Network-structure"><a href="#Network-structure" class="headerlink" title="Network structure"></a>Network structure</h4><ul>
<li><p>LR特征提取模块:这个LR特征提取模块由一个conv(3, 4m)和一个conv(3, m)组成，浅层特征提取可以由下列表达式表达：\(F_{in}^t = f_{LRFB}(I_{LR})\)</p>
</li>
<li><p>反馈模块:第t个权重共享模块的输出可以表示为：\(F_{out}^t=f_{FB}(F_{out}^{t-1},F_{in}^t)\)</p>
</li>
<li><p>第t个权重共享模块的中间监督输出：\(I_{SR}^t=I_{Res}^t+f_{UP}(I_{LR})\)其中\(I_{Res}^t=f_{RB}(F_{out}^t)\)</p>
</li>
</ul>
<h4 id="Feedback-block"><a href="#Feedback-block" class="headerlink" title="Feedback block"></a>Feedback block</h4><p><img src="http://sotavision.cn/showdoc/server/../Public/Uploads/2020-03-11/5e68feb50db97.png" alt="" loading="lazy"><br>简而言之，反馈模块就是反复上采样再下采样操作，同时，对所有上采样后的特征用dense connection，也对下采样后的特征用dense connection，中间用1*1卷积来降低计算量。<br>输入特征：\(L_0^t = C_0([F_{out}^{t-1},F_{in}^t])\)<br>上采样后的特征：\(H_g^t = C_g^{\uparrow}([L_0^t,L_1^t,…,L_{g-1}^t])\)<br>下采样后的特征：\(L_g^t = C_g^{\downarrow}([H_1^t,H_2^t,…,H_{g-1}^t])\)<br>输出特征：\(f_{out}^t = C_{FF}([L_1^t,L_2^t,…,L_{G}^t])\)</p>
<h4 id="Loss-function"><a href="#Loss-function" class="headerlink" title="Loss function"></a>Loss function</h4><p>loss function 为：\(L({\Theta}) = \dfrac{1}{T} \displaystyle\sum_{t=1}^{T}W^t||I_{HR}^t - I_{SR}^t||\)。控制数值\(W^t\)实验中都为1。</p>
<h4 id="Curriculum-learning-strategy"><a href="#Curriculum-learning-strategy" class="headerlink" title="Curriculum learning strategy"></a>Curriculum learning strategy</h4><p> 简而言之就是，中间监督的真值会根据任务难度进行选择，比如单一的bicubic降采样退化，所有的真值都是一样的；而对于BD（bicubic+blur）退化，头两个中间监督输出用带高斯模糊的真值，之后的中间监督用不带高斯模糊的真值。</p>
<hr>
<h3 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h3><h4 id="Experiments-Details"><a href="#Experiments-Details" class="headerlink" title="Experiments Details"></a>Experiments Details</h4><p>实验细节可以参考官方代码：<a href="https://github.com/Paper99/SRFBN_CVPR19" target="_blank" rel="noopener">https://github.com/Paper99/SRFBN_CVPR19</a></p>
<h4 id="Network-analysis"><a href="#Network-analysis" class="headerlink" title="Network analysis"></a>Network analysis</h4><p>在这一小节中，我们探讨了迭代次数(表示为T)和反馈块中投影组的数目(表示为G)的影响。</p>
<blockquote>
<p><img src="http://sotavision.cn/showdoc/server/../Public/Uploads/2020-03-11/5e6906c0a2c1c.png" alt="" loading="lazy"></p>
</blockquote>
<p>选择更大的T或G都有助于取得更好的结果。值得注意的是，小T和G仍然优于VDSR</p>
<h4 id="Comparisons-with-state-of-the-arts"><a href="#Comparisons-with-state-of-the-arts" class="headerlink" title="Comparisons with state-of-the-arts"></a>Comparisons with state-of-the-arts</h4><blockquote>
<p><img src="http://sotavision.cn/showdoc/server/../Public/Uploads/2020-03-11/5e69077a67a19.png" alt="" loading="lazy"></p>
</blockquote>
<h4 id="Results-with-BI-degradation-model"><a href="#Results-with-BI-degradation-model" class="headerlink" title="Results with BI degradation model"></a>Results with BI degradation model</h4><blockquote>
<p><img src="http://sotavision.cn/showdoc/server/../Public/Uploads/2020-03-11/5e6909a18b73d.png" alt="" loading="lazy"><br>这里没用放RCAN和RDN的数据，实际上SRFBN没达到SOTA，现在最好的还是RCAN</p>
</blockquote>
<h4 id="Results-with-BD-and-DN-degradation-models"><a href="#Results-with-BD-and-DN-degradation-models" class="headerlink" title="Results with BD and DN degradation models"></a>Results with BD and DN degradation models</h4><blockquote>
<p><img src="http://sotavision.cn/showdoc/server/../Public/Uploads/2020-03-11/5e6909ac81cd8.png" alt="" loading="lazy"></p>
</blockquote>
<hr>
<h3 id="Conclusions"><a href="#Conclusions" class="headerlink" title="Conclusions"></a>Conclusions</h3><p>本文提出了一种新的图像SR网络-超分辨率反馈网络(SRFBN)，通过增强高层次的图像表示来忠实地重建SR图像。网络中的反馈块(FB)可以有效地处理反馈信息流和特征重用。此外，还提出了一种curriculum学习策略，使网络能够很好地适应复杂退化模型破坏低分辨率图像的复杂任务。综合实验结果表明，所提出的SRFBN能以极小的参数提供与现有方法相比的比较或更好的性能。</p>
</div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>秩同道合</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="http://alexzou14.github.io/2020/04/08/SRFBN/" title="Feedback Network for Image Super-Resolution论文阅读笔记">http://alexzou14.github.io/2020/04/08/SRFBN/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>本博客所有文章除特别声明外，均默认采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0 "><svg class="icon"><use xlink:href="#icon-creative-commons-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-by-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-nc-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-sa-line"></use></svg></a> 许可协议。</li></ul></section></article><div class="post-nav"><div class="post-nav-item"></div><div class="post-nav-item"><a class="post-nav-next" href="/2020/04/08/GuideSR/" rel="next" title="Guided Super-Resolution as Pixel-to-Pixel Transformation论文阅读笔记"><span class="post-nav-text">Guided Super-Resolution as Pixel-to-Pixel Transformation论文阅读笔记</span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-right-s-line"></use></svg></a></div></div><div id="comment"><div class="comment-tooltip text-center"><span>若您无 GitHub 账号，可直接在下方匿名评论。</span><br><span>若您想及时得到回复提醒，建议跳转 GitHub Issues 评论。</span><br><span>若没有本文 Issue，您可以使用 Comment 模版新建。</span><br><a class="hty-button hty-button--raised" id="github-issues" href="https://github.com/AlexZou14/alexzou14.github.io/issues?q=is:issue+Feedback Network for Image Super-Resolution论文阅读笔记" target="_blank" rel="noopener">GitHub Issues</a></div><div class="comment-container" id="valine-container"></div></div><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.css"><script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script></div></main><footer class="sidebar-translate" id="footer"><div class="copyright"><span>&copy; 2019 – 2020 </span><span class="with-love" id="animate"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-cloud-line"></use></svg></span><span class="author"> 秩同道合</span></div><div class="powered"><span>由 <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a> 驱动 v4.2.0</span><span class="footer-separator">|</span><span>主题 - <a rel="noopener" href="https://github.com/YunYouJun/hexo-theme-yun" target="_blank"><span>Yun</span></a> v0.3.1</span></div><script defer src="https://cdn.jsdelivr.net/npm/valine@latest/dist/Valine.min.js"></script><script>function initValine() {
  new Valine(CONFIG.valine);
}
document.addEventListener("DOMContentLoaded", function() {
  initValine();
});</script></footer><a class="hty-icon-button" id="goUp" aria-label="back-to-top" href="#"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-up-s-line"></use></svg></a></div><script defer src="/js/utils.js"></script><script defer src="/js/hexo-theme-yun.js"></script><script src="https://cdn.jsdelivr.net/npm/live2d-widget@^3.1.3/lib/L2Dwidget.min.js"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"https://cdn.jsdelivr.net/npm/live2d-widget-model-hijiki@1.0.5/assets/hijiki.model.json"},"display":{"position":"right","width":200,"height":400},"mobile":{"show":true},"react":{"opacity":0.8},"dialog":{"enable":true,"hitokoto":true},"log":false});</script></body></html>