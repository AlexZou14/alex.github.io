<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="description" content="Embedded Block Residual Network:A Recursive Restoration Model for Single-Image Super-Resolution 论文阅读笔记"><meta name="keywords" content="深度学习,笔记,超分辨率"><meta name="author" content="秩同道合"><meta name="copyright" content="秩同道合"><meta name="theme-color" content="#0078E7"><title>Embedded Block Residual Network:A Recursive Restoration Model for Single-Image Super-Resolution 论文阅读笔记 | 秩同道合的小站</title><link rel="shortcut icon" href="https://cdn.jsdelivr.net/gh/AlexZou14/CDN/img/favicon.ico"><link rel="preload" href="/css/hexo-theme-yun.css" as="style"><link rel="preload" href="/js/utils.js" as="script"><link rel="preload" href="/js/hexo-theme-yun.js" as="script"><link rel="prefetch" href="/js/sidebar.js" as="script"><link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin><link rel="stylesheet" href="/css/hexo-theme-yun.css"><link rel="alternate" href="/atom.xml" title="秩同道合的小站"><script id="yun-config">
    let Yun = window.Yun || {};
    let CONFIG = {"root":"/","title":"秩同道合的小站","version":"0.3.1","anonymous_image":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/avatar/none.jpg","say":{"api":"https://v1.hitokoto.cn","hitokoto":true},"valine":{"el":"#valine-container","verify":false,"notify":false,"appId":"eCgP91hRSX8OtvCIR4MgLfcl-gzGzoHsz","appKey":"N5gVT8kUx5O0wMvc47SU040Y","serverURLs":null,"placeholder":"大佬求指教&nbsp_(:з」∠)_ （填写邮箱可以收到回复通知～）","avatar":null,"meta":["nick","mail","link"],"pageSize":10,"lang":"zh-cn","visitor":true},"fireworks":{"colors":["102, 167, 221","62, 131, 225","33, 78, 194"]}};
  </script><script src="//at.alicdn.com/t/font_1140697_pa6cswvjpq.js" async></script><meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="秩同道合的小站" type="application/atom+xml">
</head><body><script defer src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script defer src="/js/ui/fireworks.js"></script><canvas class="fireworks"></canvas><div class="container"><a class="sidebar-toggle sidebar-toggle-fixed hty-icon-button"><div class="hamburger hamburger--spin" type="button"><span class="hamburger-box"><span class="hamburger-inner"></span></span></div></a><aside class="sidebar"><ul class="sidebar-nav"><li class="sidebar-nav-item sidebar-nav-toc sidebar-nav-active hty-icon-button" data-target="post-toc-wrap" title="文章目录"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-list-ordered"></use></svg></li><li class="sidebar-nav-item sidebar-nav-overview hty-icon-button" data-target="site-overview-wrap" title="站点概览"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-passport-line"></use></svg></li></ul><div class="sidebar-panel" id="site-overview-wrap"><div class="site-info fix-top"><a class="site-author-avatar" href="/about" title="秩同道合"><img loading="lazy" src="https://cdn.jsdelivr.net/gh/AlexZou14/CDN/img/touxiang.jpg" alt="秩同道合"></a><div class="site-author-name"><a href="/about">秩同道合</a></div><a class="site-name" href="/about/site.html">秩同道合的小站</a><sub class="site-subtitle">寻找志趣相投的伙伴！</sub><div class="site-desciption">我和你，以及我们的秩相同所以我们才等价！</div></div><nav class="site-state"><a class="site-state-item hty-icon-button icon-home" href="/" title="首页"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-home-4-line"></use></svg></span></a><div class="site-state-item site-state-posts"><a href="/archives" title="归档"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-archive-line"></use></svg></span><span class="site-state-item-count">30</span></a></div><div class="site-state-item site-state-categories"><a href="/categories" title="分类"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-2-line"></use></svg></span><span class="site-state-item-count">2</span></a></div><div class="site-state-item site-state-tags"><a href="/tags" title="标签"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="site-state-item-count">5</span></a></div><a class="site-state-item hty-icon-button" href="https://github.com/AlexZou14" target="_blank" rel="noopener" title="reward.comment"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-hand-coin-line"></use></svg></span></a></nav><hr style="margin-bottom:0.5rem"><div class="links-of-author"><a class="links-of-author-item hty-icon-button" rel="noopener" href="/atom.xml" title="RSS" target="_blank" style="color:orange"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-rss-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://github.com/AlexZou14" title="GitHub" target="_blank" style="color:#181717"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-github-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="mailto:1120375574@qq.com" title="E-Mail" target="_blank" style="color:#8E71C1"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-mail-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://space.bilibili.com/19164044" title="哔哩哔哩" target="_blank" style="color:#FF8EB3"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-bilibili-line"></use></svg></a></div><hr style="margin:0.5rem 1rem"><div class="links"><a class="links-item hty-icon-button" href="http://sotavision.cn" target="_blank" rel="noopener" title="工作组" style="color:#000000"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-send-plane-2-line"></use></svg></a></div></div><script defer src="/js/sidebar.js"></script><div class="sidebar-panel sidebar-panel-active" id="post-toc-wrap"><div class="post-toc"><div class="post-toc-progress"><div class="progress-bar"></div><div class="progress-info"><span class="progress-notice">您已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span></div></div><div class="post-toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#Abstract"><span class="toc-number">1.</span> <span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Introduction"><span class="toc-number">2.</span> <span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Related-work"><span class="toc-number">3.</span> <span class="toc-text">Related work</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Proposed-Method"><span class="toc-number">4.</span> <span class="toc-text">Proposed Method</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Block-Residual-Module"><span class="toc-number">4.1.</span> <span class="toc-text">Block Residual Module</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Loss-Function"><span class="toc-number">4.2.</span> <span class="toc-text">Loss Function</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Experiment"><span class="toc-number">5.</span> <span class="toc-text">Experiment</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Experiments-Details"><span class="toc-number">5.1.</span> <span class="toc-text">Experiments Details</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#EBRN-VS-other-Network"><span class="toc-number">5.2.</span> <span class="toc-text">EBRN VS other Network</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#EBRN-VS-Residual-Network"><span class="toc-number">5.2.1.</span> <span class="toc-text">EBRN VS Residual Network</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#EBRN-VS-Deep-Back-Projection-Network"><span class="toc-number">5.2.2.</span> <span class="toc-text">EBRN VS Deep Back-Projection Network</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Model-Analyses"><span class="toc-number">5.3.</span> <span class="toc-text">Model Analyses</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#运行速度、最优BRM数验证"><span class="toc-number">5.4.</span> <span class="toc-text">运行速度、最优BRM数验证</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Comparisons-with-state-of-the-arts"><span class="toc-number">5.5.</span> <span class="toc-text">Comparisons with state-of-the-arts</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Conclusions"><span class="toc-number">6.</span> <span class="toc-text">Conclusions</span></a></li></ol></div></div></div></aside><main class="sidebar-translate" id="content"><div id="post"><article class="post-block" itemscope itemtype="http://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://alexzou14.github.io/2020/04/10/EBRN/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="秩同道合"><meta itemprop="description" content="Embedded Block Residual Network:A Recursive Restoration Model for Single-Image Super-Resolution 论文阅读笔记"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="秩同道合的小站"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">Embedded Block Residual Network:A Recursive Restoration Model for Single-Image Super-Resolution 论文阅读笔记</h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-calendar-line"></use></svg></span> <time title="创建时间：2020-04-10 21:27:05" itemprop="dateCreated datePublished" datetime="2020-04-10T21:27:05+08:00">2020-04-10</time></span><div class="post-count"><span class="post-symbolcount"><span class="post-meta-item-icon" title="本文字数"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-file-word-line"></use></svg></span> <span title="本文字数">6.5k</span><span class="post-meta-divider">-</span><span class="post-meta-item-icon" title="阅读时长"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-timer-line"></use></svg></span> <span title="阅读时长">13 分钟</span></span></div><span class="leancloud_visitors" id="/2020/04/10/EBRN/" data-flag-title="Embedded Block Residual Network:A Recursive Restoration Model for Single-Image Super-Resolution 论文阅读笔记"><span class="post-meta-item-icon" title="阅读次数"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-eye-line"></use></svg> <span class="leancloud-visitors-count"></span></span></span><div class="post-classify"><span class="post-category"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-line"></use></svg></span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a class="category" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="text">论文笔记</span></a></span></span><span class="post-tag"><span class="post-meta-divider">-</span><a class="tag" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">深度学习</span></a><a class="tag" href="/tags/%E7%AC%94%E8%AE%B0/"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">笔记</span></a><a class="tag" href="/tags/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87/"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">超分辨率</span></a></span></div></div></header><section class="post-body" itemprop="articleBody"><div class="post-content post-markdown"><h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>当时的单一图像超分领域中，比较好的方法都是通过比较复杂的卷积网络或者递归神经网络来得到。但是，这些方法都试图用一个模型去恢复图像中的所有结构和纹理，这样就会在处理高频细节的时忽略低频纹理。所以，图片的低频和高频信息的复杂程度是不一样的，因此在对这两部分信息进行恢复的时候，应该使用具有不同复杂度的模型或者是不同深度的网络结构。本文就提出了一种EBRN，不同模块储存不同的频率信息，浅层网络处理低频信息，深层网络处理高频信息。</p>
<hr>
<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>由于单一图像超分辨的问题存在不定性，所以单一图像超分辨率领域在近些年飞速发展，有很多的超分方法被提出，尤其是近几年学习方法在超分领域的应用，大多数方法都是在致力于训练更深更大的网络来恢复图像，这样的网络在设计中参数数量增大连接过程更加巧妙，需要更多的trick来处理这个网络。可是图片的低频和高频信息的复杂程度是不一样的，因此在对这两部分信息进行恢复的时候，应该使用具有不同复杂度的模型或者是不同深度的网络结构。如果对这两部分信息使用同样的网络结构或者模型进行恢复的话，会出现如下情形：</p>
<blockquote>
<p><img src="http://sotavision.cn/showdoc/server/../Public/Uploads/2020-03-04/5e5f169065599.png" alt="" loading="lazy"></p>
</blockquote>
<p>即用浅层的网络能够很好地拟合对低频信息进行恢复所需的函数，但是高频信息由于函数更为复杂，低层的网络结构的学习能力有限，对于高频信息是欠学习的(underfit)；而用深层的网络能够很好地拟合对高频信息进行恢复所需的函数，但是对于低频信息而言，属于过拟合(overfit)。所以不同深度网络适应不同频率的信息。<br>本文主要贡献有:</p>
<ul>
<li>图片的低频和高频信息的复杂程度是不一样的，因此在对这两部分信息进行恢复的时候，应该使用具有不同复杂度的模型或者是不同深度的网络结构</li>
<li>提出了一种块残差模块（BRM），它试图恢复图像结构和纹理，同时将难以恢复的信息传递给更深层次的模块</li>
<li>提出了一种新的嵌入多个BRM的技术，它可以有效地提高基于每个模块输出的最终重建质量.</li>
</ul>
<hr>
<h3 id="Related-work"><a href="#Related-work" class="headerlink" title="Related work"></a>Related work</h3><p>SISR问题在现存的文献中存在的方法可以分为3大类：基于插值方法，基于重建的方法，基于学习的方法。当前超分辨问题的研究方向有以下几个方面：</p>
<ul>
<li>通过优化CNN模型框架，介绍了基于深度学习的超分辨率经典模型，包括SRCNN、VDSR、DRCN、EDSR等，这些模型都是基于优化PSNR/SSIM的；</li>
<li>基于优化损失函数：较为常见的有L1、L2，以及后来的perceptual loss 和adversarial loss.介绍了基于优化感知损失的SRGAN 、SFTGAN模型。</li>
<li>基于扩大放大倍数上，x2,x3,x4的研究工作已经快接近瓶颈，x8放大成为研究热点。</li>
</ul>
<p>通过文献阅读，当前没有人研究模型复杂度和图像频率信息，本文就是基于此开展研究的。</p>
<hr>
<h3 id="Proposed-Method"><a href="#Proposed-Method" class="headerlink" title="Proposed Method"></a>Proposed Method</h3><p>基于上述的出发点，作者的策略是对于低频的信息，使用一个大网络结构中的浅层网络进行恢复，对于高频信息，使用一个大网络结构中的深层网络进行恢复。因为对于一个网络结构而言，其中深层的层相比于浅层而言，具有更强的函数拟合能力。因此，作者只需要将图片中的不同频率的信息交由不同深度的网络进行恢复即可。作者的整体网络结构图如下所示：</p>
<blockquote>
<p><img src="http://sotavision.cn/showdoc/server/../Public/Uploads/2020-03-04/5e5f1f4a52d7c.png" alt="" loading="lazy"></p>
</blockquote>
<h4 id="Block-Residual-Module"><a href="#Block-Residual-Module" class="headerlink" title="Block Residual Module"></a>Block Residual Module</h4><p>从该图可以看出，浅层的网络恢复低频信息，深层的网络恢复高频信息，最后再将这些信息进行concat便得到了最终的超分图片。那么现在的问题是如何在同一个网络结构下，使用不同深度的网络对不同频率的信息进行恢复。针对此，作者设计了一个网络模块BRM，如下图所示：</p>
<blockquote>
<p><img src="http://sotavision.cn/showdoc/server/../Public/Uploads/2020-03-04/5e5f28c62f5eb.png" alt="" loading="lazy"></p>
</blockquote>
<p>这个模块的作用是使用当前深度的网络恢复部分HR信息，同时将没有恢复的信息(相对来说属于高频的信息)传至更深的网络中进行恢复。这个模块有两个分支：super-resolution flow和back-projection flow。</p>
<ul>
<li>super-resolution flow: 对输入的信息(低分辨率特征层)进行超分。</li>
<li>back-projection flow: 对super-resolution flow的超分图片进行一个下采样，得到一个低分辨率特征层，之后用输出的低分辨率特征层减去这个低分辨率，就能得到此时还没有恢复的信息。之后再将这部分信息输入到一个残差模块，之后将输出的信息输入到下一个RBM模块。</li>
</ul>
<p>为什么相减能得到没有恢复的信息：因为原始的LR图片是由HR图片进行bicubic降采样得到的，而用LR超分得到的当前的SR图片的信息肯定是小于HR的，因此对SR进行下采样得到的\(LR’\)的信息肯定是小于\(LR\)的，所以相减就能得到当前深度的网络还没有恢复的信息。<br>之后便是如何对这些恢复的不同频率的信息进行结合了，其中作者发现较深的网络恢复的信息能够提高浅层网络的信息恢复效果，因此提出了一个recursive fusion的方法，这个应该是通过尝试多种不同的信息融合方式所得到的结果,fusion process是：\(O’_x = f(O_x+O’_{x+1})\)</p>
<h4 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a>Loss Function</h4><p>这里作者先用L1loss快速收敛，让后用L2loss微调模型参数。</p>
<hr>
<h3 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h3><h4 id="Experiments-Details"><a href="#Experiments-Details" class="headerlink" title="Experiments Details"></a>Experiments Details</h4><p>作者暂未公开代码，可以依照原文自己复现。</p>
<h4 id="EBRN-VS-other-Network"><a href="#EBRN-VS-other-Network" class="headerlink" title="EBRN VS other Network"></a>EBRN VS other Network</h4><h5 id="EBRN-VS-Residual-Network"><a href="#EBRN-VS-Residual-Network" class="headerlink" title="EBRN VS Residual Network"></a>EBRN VS Residual Network</h5><p>与传统CNN模型相比，残差网络的优势在于残差学习促进了网络中特征的传输，缓解了梯度消失问题，使得网络更容易训练。<br>在这项工作中，我们利用了不同于传统的残差网络的残差学习思想。例如：</p>
<ol>
<li>由于BN层限制了特征归一化过程中中间特征的范围灵活性，所以本文模型没有使用batch normalization (BN)层。</li>
<li>另一个重要的区别是残差是如何计算的以及残差所传达的信息。在残差网络中，剩余信号是输入和输出的差值。在该模型中，一种残差信号是某一频率范围内的信息;残差信号的另一种类型是原始LR特征与反投影LR特征之间的差异。在每一个BRM中，第二个残差信号对于SR是很重要的，因为它明确地传达了哪些信息需要后续BRM恢复。</li>
</ol>
<h5 id="EBRN-VS-Deep-Back-Projection-Network"><a href="#EBRN-VS-Deep-Back-Projection-Network" class="headerlink" title="EBRN VS Deep Back-Projection Network"></a>EBRN VS Deep Back-Projection Network</h5><p>DBPN：该方法利用迭代的上下采样层，为每个阶段的投影误差提供了误差反馈机制。误差可以有效地提高模型中深层的恢复效果。<br>两种方法的不同之处在于:</p>
<ol>
<li>在上投影单元和下投影单元中，DBPN将LR残差直接映射到HR空间，而我们的模型中LR残差包含更高频率的信息，这些信息被反馈到更深的子网络中进行恢复;</li>
<li>DBPN利用LR残差和HR残差，目标是每个上、下投影单元尽量减小残差，而我们的方法将残差信号与不同频率的信息联系起来，每个BRM负责恢复相应的信息。动机的不同导致模型的参数比DBPN少，但性能比DBPN有提高。</li>
</ol>
<h4 id="Model-Analyses"><a href="#Model-Analyses" class="headerlink" title="Model Analyses"></a>Model Analyses</h4><p>为了验证这一点，我们在图中演示了不同频段上不同BRM输出的能量分布。利用小波变换的不同能级系数，计算了能量在不同频段的分布。结果表明，浅层BRMs的输出包含更多的低频信息，而深层BRMs的输出则倾向于恢复更多的高频信息。</p>
<blockquote>
<p><img src="http://sotavision.cn/showdoc/server/../Public/Uploads/2020-03-04/5e5f356e406e3.png" alt="" loading="lazy"></p>
</blockquote>
<h4 id="运行速度、最优BRM数验证"><a href="#运行速度、最优BRM数验证" class="headerlink" title="运行速度、最优BRM数验证"></a>运行速度、最优BRM数验证</h4><p><img src="http://sotavision.cn/showdoc/server/../Public/Uploads/2020-03-04/5e5f35dc49d26.png" alt="" loading="lazy"></p>
<h4 id="Comparisons-with-state-of-the-arts"><a href="#Comparisons-with-state-of-the-arts" class="headerlink" title="Comparisons with state-of-the-arts"></a>Comparisons with state-of-the-arts</h4><blockquote>
<p><img src="http://sotavision.cn/showdoc/server/../Public/Uploads/2020-03-04/5e5f363b00d9b.png" alt="" loading="lazy"><br><img src="http://sotavision.cn/showdoc/server/../Public/Uploads/2020-03-04/5e5f362b6df91.png" alt="" loading="lazy"></p>
</blockquote>
<hr>
<h3 id="Conclusions"><a href="#Conclusions" class="headerlink" title="Conclusions"></a>Conclusions</h3><ul>
<li>作者提出了图片的低频和高频信息的复杂程度是不一样的，因此在对这两部分信息进行恢复的时候，应该使用具有不同复杂度的模型或者是不同深度的网络结构</li>
<li>提出了一种块残差模块（BRM），它试图恢复图像结构和纹理，同时将难以恢复的信息传递给更深层次的模块</li>
<li>提出了一种新的嵌入多个BRM的技术，它可以有效地提高基于每个模块输出的最终重建质量.</li>
</ul>
</div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>秩同道合</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="http://alexzou14.github.io/2020/04/10/EBRN/" title="Embedded Block Residual Network:A Recursive Restoration Model for Single-Image Super-Resolution 论文阅读笔记">http://alexzou14.github.io/2020/04/10/EBRN/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>本博客所有文章除特别声明外，均默认采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0 "><svg class="icon"><use xlink:href="#icon-creative-commons-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-by-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-nc-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-sa-line"></use></svg></a> 许可协议。</li></ul></section></article><div class="post-nav"><div class="post-nav-item"><a class="post-nav-prev" href="/2020/04/11/VDSR/" rel="prev" title="Accurate Image Super-Resolution Using Very Deep Convolutional Networks论文阅读笔记"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-left-s-line"></use></svg><span class="post-nav-text">Accurate Image Super-Resolution Using Very Deep Convolutional Networks论文阅读笔记</span></a></div><div class="post-nav-item"><a class="post-nav-next" href="/2020/04/10/SRNTT/" rel="next" title="Image Super-Resolution by Neural Texture Transfer论文阅读笔记"><span class="post-nav-text">Image Super-Resolution by Neural Texture Transfer论文阅读笔记</span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-right-s-line"></use></svg></a></div></div><div id="comment"><div class="comment-tooltip text-center"><span>若您无 GitHub 账号，可直接在下方匿名评论。</span><br><span>若您想及时得到回复提醒，建议跳转 GitHub Issues 评论。</span><br><span>若没有本文 Issue，您可以使用 Comment 模版新建。</span><br><a class="hty-button hty-button--raised" id="github-issues" href="https://github.com/AlexZou14/alexzou14.github.io/issues?q=is:issue+Embedded Block Residual Network:A Recursive Restoration Model for Single-Image Super-Resolution 论文阅读笔记" target="_blank" rel="noopener">GitHub Issues</a></div><div class="comment-container" id="valine-container"></div></div><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.css"><script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script></div></main><footer class="sidebar-translate" id="footer"><div class="copyright"><span>&copy; 2019 – 2021 </span><span class="with-love" id="animate"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-cloud-line"></use></svg></span><span class="author"> 秩同道合</span></div><div class="powered"><span>由 <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a> 驱动 v4.2.0</span><span class="footer-separator">|</span><span>主题 - <a rel="noopener" href="https://github.com/YunYouJun/hexo-theme-yun" target="_blank"><span>Yun</span></a> v0.3.1</span></div><script defer src="https://cdn.jsdelivr.net/npm/valine@latest/dist/Valine.min.js"></script><script>function initValine() {
  new Valine(CONFIG.valine);
}
document.addEventListener("DOMContentLoaded", function() {
  initValine();
});</script></footer><a class="hty-icon-button" id="goUp" aria-label="back-to-top" href="#"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-up-s-line"></use></svg></a></div><script defer src="/js/utils.js"></script><script defer src="/js/hexo-theme-yun.js"></script><script src="https://cdn.jsdelivr.net/npm/live2d-widget@^3.1.3/lib/L2Dwidget.min.js"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"https://cdn.jsdelivr.net/npm/live2d-widget-model-hijiki@1.0.5/assets/hijiki.model.json"},"display":{"position":"right","width":200,"height":400},"mobile":{"show":true},"react":{"opacity":0.8},"dialog":{"enable":true,"hitokoto":true},"log":false});</script></body></html>