<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="description" content="Image Super-Resolution via Deep Recursive Residual Network论文阅读笔记"><meta name="keywords" content="深度学习,笔记,超分辨率"><meta name="author" content="秩同道合"><meta name="copyright" content="秩同道合"><meta name="theme-color" content="#0078E7"><title>Image Super-Resolution via Deep Recursive Residual Network论文阅读笔记 | 秩同道合的小站</title><link rel="shortcut icon" href="https://cdn.jsdelivr.net/gh/AlexZou14/CDN/img/favicon.ico"><link rel="preload" href="/css/hexo-theme-yun.css" as="style"><link rel="preload" href="/js/utils.js" as="script"><link rel="preload" href="/js/hexo-theme-yun.js" as="script"><link rel="prefetch" href="/js/sidebar.js" as="script"><link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin><link rel="stylesheet" href="/css/hexo-theme-yun.css"><link rel="alternate" href="/atom.xml" title="秩同道合的小站"><script id="yun-config">
    let Yun = window.Yun || {};
    let CONFIG = {"root":"/","title":"秩同道合的小站","version":"0.3.1","anonymous_image":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/avatar/none.jpg","say":{"api":"https://v1.hitokoto.cn","hitokoto":true},"valine":{"el":"#valine-container","verify":false,"notify":false,"appId":"eCgP91hRSX8OtvCIR4MgLfcl-gzGzoHsz","appKey":"N5gVT8kUx5O0wMvc47SU040Y","serverURLs":null,"placeholder":"大佬求指教&nbsp_(:з」∠)_ （填写邮箱可以收到回复通知～）","avatar":null,"meta":["nick","mail","link"],"pageSize":10,"lang":"zh-cn","visitor":true},"fireworks":{"colors":["102, 167, 221","62, 131, 225","33, 78, 194"]}};
  </script><script src="//at.alicdn.com/t/font_1140697_pa6cswvjpq.js" async></script><meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="秩同道合的小站" type="application/atom+xml">
</head><body><script defer src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script defer src="/js/ui/fireworks.js"></script><canvas class="fireworks"></canvas><div class="container"><a class="sidebar-toggle sidebar-toggle-fixed hty-icon-button"><div class="hamburger hamburger--spin" type="button"><span class="hamburger-box"><span class="hamburger-inner"></span></span></div></a><aside class="sidebar"><ul class="sidebar-nav"><li class="sidebar-nav-item sidebar-nav-toc sidebar-nav-active hty-icon-button" data-target="post-toc-wrap" title="文章目录"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-list-ordered"></use></svg></li><li class="sidebar-nav-item sidebar-nav-overview hty-icon-button" data-target="site-overview-wrap" title="站点概览"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-passport-line"></use></svg></li></ul><div class="sidebar-panel" id="site-overview-wrap"><div class="site-info fix-top"><a class="site-author-avatar" href="/about" title="秩同道合"><img loading="lazy" src="https://cdn.jsdelivr.net/gh/AlexZou14/CDN/img/touxiang.jpg" alt="秩同道合"></a><div class="site-author-name"><a href="/about">秩同道合</a></div><a class="site-name" href="/about/site.html">秩同道合的小站</a><sub class="site-subtitle">寻找志趣相投的伙伴！</sub><div class="site-desciption">我和你，以及我们的秩相同所以我们才等价！</div></div><nav class="site-state"><a class="site-state-item hty-icon-button icon-home" href="/" title="首页"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-home-4-line"></use></svg></span></a><div class="site-state-item site-state-posts"><a href="/archives" title="归档"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-archive-line"></use></svg></span><span class="site-state-item-count">8</span></a></div><div class="site-state-item site-state-categories"><a href="/categories" title="分类"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-2-line"></use></svg></span><span class="site-state-item-count">1</span></a></div><div class="site-state-item site-state-tags"><a href="/tags" title="标签"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="site-state-item-count">3</span></a></div><a class="site-state-item hty-icon-button" href="https://github.com/AlexZou14" target="_blank" rel="noopener" title="reward.comment"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-hand-coin-line"></use></svg></span></a></nav><hr style="margin-bottom:0.5rem"><div class="links-of-author"><a class="links-of-author-item hty-icon-button" rel="noopener" href="/atom.xml" title="RSS" target="_blank" style="color:orange"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-rss-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://github.com/AlexZou14" title="GitHub" target="_blank" style="color:#181717"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-github-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="mailto:1120375574@qq.com" title="E-Mail" target="_blank" style="color:#8E71C1"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-mail-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://space.bilibili.com/19164044" title="哔哩哔哩" target="_blank" style="color:#FF8EB3"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-bilibili-line"></use></svg></a></div><hr style="margin:0.5rem 1rem"><div class="links"><a class="links-item hty-icon-button" href="http://sotavision.cn" target="_blank" rel="noopener" title="工作组" style="color:#000000"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-send-plane-2-line"></use></svg></a></div></div><script defer src="/js/sidebar.js"></script><div class="sidebar-panel sidebar-panel-active" id="post-toc-wrap"><div class="post-toc"><div class="post-toc-progress"><div class="progress-bar"></div><div class="progress-info"><span class="progress-notice">您已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span></div></div><div class="post-toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#Abstract"><span class="toc-number">1.</span> <span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Introduction"><span class="toc-number">2.</span> <span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Related-work"><span class="toc-number">3.</span> <span class="toc-text">Related work</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#SResNet"><span class="toc-number">3.1.</span> <span class="toc-text">SResNet</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#VDSR"><span class="toc-number">3.2.</span> <span class="toc-text">VDSR</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#DRCN"><span class="toc-number">3.3.</span> <span class="toc-text">DRCN</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Proposed-Method"><span class="toc-number">4.</span> <span class="toc-text">Proposed Method</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Network-structure"><span class="toc-number">4.1.</span> <span class="toc-text">Network structure</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Residual-Unit"><span class="toc-number">4.2.</span> <span class="toc-text">Residual Unit</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Recursive-Block"><span class="toc-number">4.3.</span> <span class="toc-text">Recursive Block</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Network-Structure"><span class="toc-number">4.4.</span> <span class="toc-text">Network Structure</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Loss-function"><span class="toc-number">4.5.</span> <span class="toc-text">Loss function</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Experiment"><span class="toc-number">5.</span> <span class="toc-text">Experiment</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Experiments-Details"><span class="toc-number">5.1.</span> <span class="toc-text">Experiments Details</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Study-of-B-and-U"><span class="toc-number">5.2.</span> <span class="toc-text">Study of B and U</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Comparisons-with-state-of-the-arts"><span class="toc-number">5.3.</span> <span class="toc-text">Comparisons with state-of-the-arts</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Conclusions"><span class="toc-number">6.</span> <span class="toc-text">Conclusions</span></a></li></ol></div></div></div></aside><main class="sidebar-translate" id="content"><div id="post"><article class="post-block" itemscope itemtype="http://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://alexzou14.github.io/2020/04/07/DRRN/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="秩同道合"><meta itemprop="description" content="Image Super-Resolution via Deep Recursive Residual Network论文阅读笔记"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="秩同道合的小站"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">Image Super-Resolution via Deep Recursive Residual Network论文阅读笔记</h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-calendar-line"></use></svg></span> <time title="创建时间：2020-04-07 18:47:09" itemprop="dateCreated datePublished" datetime="2020-04-07T18:47:09+08:00">2020-04-07</time></span><div class="post-count"><span class="post-symbolcount"><span class="post-meta-item-icon" title="本文字数"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-file-word-line"></use></svg></span> <span title="本文字数">6.6k</span><span class="post-meta-divider">-</span><span class="post-meta-item-icon" title="阅读时长"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-timer-line"></use></svg></span> <span title="阅读时长">13 分钟</span></span></div><span class="leancloud_visitors" id="/2020/04/07/DRRN/" data-flag-title="Image Super-Resolution via Deep Recursive Residual Network论文阅读笔记"><span class="post-meta-item-icon" title="阅读次数"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-eye-line"></use></svg> <span class="leancloud-visitors-count"></span></span></span><div class="post-classify"><span class="post-category"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-line"></use></svg></span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a class="category" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="text">论文笔记</span></a></span></span><span class="post-tag"><span class="post-meta-divider">-</span><a class="tag" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">深度学习</span></a><a class="tag" href="/tags/%E7%AC%94%E8%AE%B0/"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">笔记</span></a><a class="tag" href="/tags/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87/"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">超分辨率</span></a></span></div></div></header><section class="post-body" itemprop="articleBody"><div class="post-content post-markdown"><h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>因为卷积神经网络可以有效的学习低分辨率到高分辨率图像的非线性映射，所以在当时基于卷积神经网络的模型在单一图像超分辨率的问题上取得了巨大成功。同时CNN模型要耗费大量的运算资源，网络参数非常多。因此本文提出了一种非常深的残差网络，使用递归学习来控制参数数目和增加深度残差学习减少网络的训练难度。</p>
<hr>
<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>由于SISR的目标是从LR图像上还原其中高频信息，所以这个问题应用很广，在医疗成像，安全监控等。在近期，CNN方法广泛的应用与解决各种不定问题，SISR问题自从SRCNN将CNN方法引入到图像超分辨率问题中，CNN方法在超分领域取得了很大的进步。作者回顾了当时众多方法的优缺点，SRCNN的计算成本高，后面就有人提出了ESPCN用亚像素卷积恢复图像，提高了图像恢复的效率。SRCNN的网络很浅，得到的结论不全对，后面Kim提出的VDSR利用比较深的网络和跳跃连接来恢复图像。后面为了减少网络参数，提出了DRCN利用递归来减少网络的参数。现在该领域存在的问题就是非常深的网络需要非常多的参数，大模型网络需要很大的存储空间，对移动系统的适应度很差。<br>作者受到以上方法的启发，提出了一种深度残差递归网络（DRRN）。<br>DRRN的创新点：</p>
<ol>
<li>在VDSR中只用了输入到输出端的全局残差（GRL），可以有效的降低训练深网络的难度，在此基础之上作者又添加了一个局部残差（LRL），有效的减少图像经深网络处理后细节的丢失。</li>
<li>和DRCN相比，作者提出了一个由多个残差单元组成的残差块进行参数共享，并且设计了一个多路径结构的递归块来解决梯度爆炸。</li>
</ol>
<hr>
<h3 id="Related-work"><a href="#Related-work" class="headerlink" title="Related work"></a>Related work</h3><blockquote>
<p><img src="http://sotavision.cn/showdoc/server/../Public/Uploads/2020-04-07/5e8c50dca8b27.png" alt="" loading="lazy"></p>
</blockquote>
<h4 id="SResNet"><a href="#SResNet" class="headerlink" title="SResNet"></a>SResNet</h4><p>ResNet中的残差学习框架简化了深度网络的训练，残差单元公式化为：<br>\[ F(\text x)=H(\text x)-\text x, \hat{\text x}=U(\text x)=\sigma(F(\text x,W)+h(\text x)) \]<br>h(x)为恒等映射(identity mapping)，F为残差函数，残差网络的核心就是去学习增加的残差函数F，这样的设计让网络更加容易训练并且不会产生过拟合</p>
<h4 id="VDSR"><a href="#VDSR" class="headerlink" title="VDSR"></a>VDSR</h4><p>VDSR中在输入的低分辨率图片和输出的高分辨图片之间引入了GRL，VDSR主要有三个特点</p>
<ul>
<li>VDSR在残差分支中使用了20个权重层，这能让网络的reception field增大</li>
<li>GRL(Global Residual Learning)能让VDSR快速收敛</li>
<li>通过尺度扩展，单个VDSR网络对不同尺度的图像具有较强的鲁棒性</li>
</ul>
<h4 id="DRCN"><a href="#DRCN" class="headerlink" title="DRCN"></a>DRCN</h4><p>添加更多的权层会引入更多的参数，其中模型可能会过拟合，并且可能会导致模型更大难以存储和复现，为了解决这些问题，作者在网络中引入了一个递归层，每层的递归层都是监督式的，包含三个部分:</p>
<ul>
<li>第一部分为embedding net，对输入中的特征进行提取，</li>
<li>第二层为为inference net，相当于特征的非线性变换， 将T个递归堆叠在一个递归层中，在这些递归之间共享权重</li>
<li>第三层为reconstruction net，即特征图重建</li>
</ul>
<hr>
<h3 id="Proposed-Method"><a href="#Proposed-Method" class="headerlink" title="Proposed Method"></a>Proposed Method</h3><h4 id="Network-structure"><a href="#Network-structure" class="headerlink" title="Network structure"></a>Network structure</h4><blockquote>
<p><img src="http://sotavision.cn/showdoc/server/../Public/Uploads/2020-04-07/5e8c50ce1fa5a.png" alt="" loading="lazy"></p>
</blockquote>
<p>作者在DRRN中将GRL和递归网络结合在一起使用，将多个残差单元堆积在一起，如下两幅图所示，在ResNet中，不同的残差单元对identity branch使用不同的输入，但是在DRRN中，使用了多路径结构，所有残差单元共享相同的identity branch的输入</p>
<blockquote>
<p><img src="http://sotavision.cn/showdoc/server/../Public/Uploads/2020-04-07/5e8c51101c2e9.png" alt="" loading="lazy"></p>
</blockquote>
<h4 id="Residual-Unit"><a href="#Residual-Unit" class="headerlink" title="Residual Unit"></a>Residual Unit</h4><blockquote>
<p><img src="http://sotavision.cn/showdoc/server/../Public/Uploads/2020-04-07/5e8c515dc7328.png" alt="" loading="lazy"></p>
</blockquote>
<p>在DRRN的残差单元将激活层放到了权重层的前面，通过别人的论文可知，这样的设计让网络更加容易训练,而每个残差单元之间的残差路径有助于学习高度复杂的有限元结构，同一路径有助于训练过程中的梯度反向传播，与ResNet中的链模式相比，这种模式更有利于学习，不容易过拟合，具体公式如下， 由于残差单元被递归学习，权重w在一个递归区中共享，但是在不同的递归区内不同。<br>\[ H^u=F(H^{u-1},W^u)+H^{u-1} \]<br>\[ H^u= G(H^{u-1})=F(H^{u-1},W)+H^{0} \]</p>
<h4 id="Recursive-Block"><a href="#Recursive-Block" class="headerlink" title="Recursive Block"></a>Recursive Block</h4><p>DRRN的网络结构如下图所示，通过叠加几个递归块，然后用卷积层重建LR和HR图像之间的残差。然后将剩余图像从输入LR image添加到全局标识映射中。整个DRRN网络结构如下图所示。实际上，VDSR可以看作是DRRN的一个特例。，当残差单元为0时，DRRN变为VDSR</p>
<blockquote>
<p><img src="http://sotavision.cn/showdoc/server/../Public/Uploads/2020-04-07/5e8c533c2b4c1.png" alt="" loading="lazy"></p>
</blockquote>
<p>DRRN网络中递归块的个数和残差单元数最终影响网络的性能，所以第u个残差单元可以表示为：<br>\[ H_b^u=G(H^{u-1})=F(H_b^{u-1},W_b)+H_b^0 \]<br>第b个递归块的输出可以表达为：<br>\[ \text x_b=H_b^UG^{(U)}(f_b(\text x_{b-1}))=G(G(\cdots(G(f_b(\text x_{b-1}))\cdots)) \]</p>
<h4 id="Network-Structure"><a href="#Network-Structure" class="headerlink" title="Network Structure"></a>Network Structure</h4><p>DRRN总的网络层数为：\( d=(1+2\times U)\times B +1 \)，R代表递归块,则输出的表达式为：<br>\[ \text y=D(\text x)=f_{Rec}(R_B(R_{B-1}(\cdots(R_1(\text x))\cdots)))+\text x \]</p>
<h4 id="Loss-function"><a href="#Loss-function" class="headerlink" title="Loss function"></a>Loss function</h4><p>作者在这里使用了MSE的loss function：<br>\[ L(\Theta)=\dfrac{1}{2N}\displaystyle\sum_{i=1}^N ||\tilde{\text x}^{(i)}-D(\text x^{i})||^2 \]</p>
<hr>
<h3 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h3><h4 id="Experiments-Details"><a href="#Experiments-Details" class="headerlink" title="Experiments Details"></a>Experiments Details</h4><p>实验细节可以参考官方代码：<a href="https://github.com/tyshiwo/DRRN" target="_blank" rel="noopener">https://github.com/tyshiwo/DRRN</a> CVPR17.<br>数据增强：图像翻转，旋转（90°、180°、270°），旋转后的图像水平翻转，数据量增加7倍，运用不同的放大倍数图像进行同一个模型训练，训练图像大小为31x31。</p>
<p>训练策略：SGD min-batch 128, momentum 0.9，初始学习率为0.1，每10轮学习率下降一半，同时使用梯度自动裁切技术。</p>
<p>卷积核相关：卷积核大小为3x3，个数为128</p>
<h4 id="Study-of-B-and-U"><a href="#Study-of-B-and-U" class="headerlink" title="Study of B and U"></a>Study of B and U</h4><blockquote>
<p><img src="http://sotavision.cn/showdoc/server/../Public/Uploads/2020-04-07/5e8c586b4e1ee.png" alt="" loading="lazy"></p>
</blockquote>
<p>B1U25可以使用更少的参数实现最先进的结果。</p>
<h4 id="Comparisons-with-state-of-the-arts"><a href="#Comparisons-with-state-of-the-arts" class="headerlink" title="Comparisons with state-of-the-arts"></a>Comparisons with state-of-the-arts</h4><p>利用52层的网络结构，利用递残差网络结构有两种实现方式：B1U25(k=297K), B17U1(k=7375K)(k表示参数数量)，与其他模型的比较结果如下PSNR和SSIM：</p>
<blockquote>
<p><img src="http://sotavision.cn/showdoc/server/../Public/Uploads/2020-04-07/5e8c591a3a9a0.png" alt="" loading="lazy"></p>
</blockquote>
<p>本文还利用了一种信息保真度(Information Fidelity Criterion IFC )的评价指标：</p>
<blockquote>
<p><img src="http://sotavision.cn/showdoc/server/../Public/Uploads/2020-04-07/5e8c593338956.png" alt="" loading="lazy"></p>
</blockquote>
<hr>
<h3 id="Conclusions"><a href="#Conclusions" class="headerlink" title="Conclusions"></a>Conclusions</h3><ol>
<li>针对单图像超分辨率的深度递归网络（DRRN）。</li>
<li>提出了一个增强的残差单元结构在一个递归块中递归学习</li>
<li>提出了局部残差和全局残差共同作用于网络，权值共享等提高网络的性能。</li>
</ol>
</div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>秩同道合</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="http://alexzou14.github.io/2020/04/07/DRRN/" title="Image Super-Resolution via Deep Recursive Residual Network论文阅读笔记">http://alexzou14.github.io/2020/04/07/DRRN/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>本博客所有文章除特别声明外，均默认采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0 "><svg class="icon"><use xlink:href="#icon-creative-commons-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-by-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-nc-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-sa-line"></use></svg></a> 许可协议。</li></ul></section></article><div class="post-nav"><div class="post-nav-item"><a class="post-nav-prev" href="/2020/04/07/NatSR/" rel="prev" title="Natural and Realistic Single Image Super-Resolution with Explicit Natural Manifold Discrimination论文阅读笔记"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-left-s-line"></use></svg><span class="post-nav-text">Natural and Realistic Single Image Super-Resolution with Explicit Natural Manifold Discrimination论文阅读笔记</span></a></div><div class="post-nav-item"><a class="post-nav-next" href="/2020/04/06/EhanceNet/" rel="next" title="EnhanceNet：Single ImageSuper-Resolution through Automated Texture Synthesis论文阅读笔记"><span class="post-nav-text">EnhanceNet：Single ImageSuper-Resolution through Automated Texture Synthesis论文阅读笔记</span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-right-s-line"></use></svg></a></div></div><div id="comment"><div class="comment-tooltip text-center"><span>若您无 GitHub 账号，可直接在下方匿名评论。</span><br><span>若您想及时得到回复提醒，建议跳转 GitHub Issues 评论。</span><br><span>若没有本文 Issue，您可以使用 Comment 模版新建。</span><br><a class="hty-button hty-button--raised" id="github-issues" href="https://github.com/AlexZou14/alexzou14.github.io/issues?q=is:issue+Image Super-Resolution via Deep Recursive Residual Network论文阅读笔记" target="_blank" rel="noopener">GitHub Issues</a></div><div class="comment-container" id="valine-container"></div></div><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.css"><script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script></div></main><footer class="sidebar-translate" id="footer"><div class="copyright"><span>&copy; 2019 – 2020 </span><span class="with-love" id="animate"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-cloud-line"></use></svg></span><span class="author"> 秩同道合</span></div><div class="powered"><span>由 <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a> 驱动 v4.2.0</span><span class="footer-separator">|</span><span>主题 - <a rel="noopener" href="https://github.com/YunYouJun/hexo-theme-yun" target="_blank"><span>Yun</span></a> v0.3.1</span></div><script defer src="https://cdn.jsdelivr.net/npm/valine@latest/dist/Valine.min.js"></script><script>function initValine() {
  new Valine(CONFIG.valine);
}
document.addEventListener("DOMContentLoaded", function() {
  initValine();
});</script></footer><a class="hty-icon-button" id="goUp" aria-label="back-to-top" href="#"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-up-s-line"></use></svg></a></div><script defer src="/js/utils.js"></script><script defer src="/js/hexo-theme-yun.js"></script><script src="https://cdn.jsdelivr.net/npm/live2d-widget@^3.1.3/lib/L2Dwidget.min.js"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"https://cdn.jsdelivr.net/npm/live2d-widget-model-hijiki@1.0.5/assets/hijiki.model.json"},"display":{"position":"right","width":200,"height":400},"mobile":{"show":true},"react":{"opacity":0.8},"dialog":{"enable":true,"hitokoto":true},"log":false});</script></body></html>