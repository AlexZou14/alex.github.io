<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="description" content="Toward Real-World Single Image Super-Resolution:A New Benchmark and A New Model论文阅读笔记"><meta name="keywords" content="深度学习,笔记,超分辨率"><meta name="author" content="秩同道合"><meta name="copyright" content="秩同道合"><meta name="theme-color" content="#0078E7"><title>Toward Real-World Single Image Super-Resolution:A New Benchmark and A New Model论文阅读笔记 | 秩同道合的小站</title><link rel="shortcut icon" href="https://cdn.jsdelivr.net/gh/AlexZou14/CDN/img/favicon.ico"><link rel="preload" href="/css/hexo-theme-yun.css" as="style"><link rel="preload" href="/js/utils.js" as="script"><link rel="preload" href="/js/hexo-theme-yun.js" as="script"><link rel="prefetch" href="/js/sidebar.js" as="script"><link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin><link rel="stylesheet" href="/css/hexo-theme-yun.css"><link rel="alternate" href="/atom.xml" title="秩同道合的小站"><script id="yun-config">
    let Yun = window.Yun || {};
    let CONFIG = {"root":"/","title":"秩同道合的小站","version":"0.3.1","anonymous_image":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/avatar/none.jpg","say":{"api":"https://v1.hitokoto.cn","hitokoto":true},"valine":{"el":"#valine-container","verify":false,"notify":false,"appId":"eCgP91hRSX8OtvCIR4MgLfcl-gzGzoHsz","appKey":"N5gVT8kUx5O0wMvc47SU040Y","serverURLs":null,"placeholder":"大佬求指教&nbsp_(:з」∠)_ （填写邮箱可以收到回复通知～）","avatar":null,"meta":["nick","mail","link"],"pageSize":10,"lang":"zh-cn","visitor":true},"fireworks":{"colors":["102, 167, 221","62, 131, 225","33, 78, 194"]}};
  </script><script src="//at.alicdn.com/t/font_1140697_pa6cswvjpq.js" async></script><meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="秩同道合的小站" type="application/atom+xml">
</head><body><script defer src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script defer src="/js/ui/fireworks.js"></script><canvas class="fireworks"></canvas><div class="container"><a class="sidebar-toggle sidebar-toggle-fixed hty-icon-button"><div class="hamburger hamburger--spin" type="button"><span class="hamburger-box"><span class="hamburger-inner"></span></span></div></a><aside class="sidebar"><ul class="sidebar-nav"><li class="sidebar-nav-item sidebar-nav-toc sidebar-nav-active hty-icon-button" data-target="post-toc-wrap" title="文章目录"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-list-ordered"></use></svg></li><li class="sidebar-nav-item sidebar-nav-overview hty-icon-button" data-target="site-overview-wrap" title="站点概览"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-passport-line"></use></svg></li></ul><div class="sidebar-panel" id="site-overview-wrap"><div class="site-info fix-top"><a class="site-author-avatar" href="/about" title="秩同道合"><img loading="lazy" src="https://cdn.jsdelivr.net/gh/AlexZou14/CDN/img/touxiang.jpg" alt="秩同道合"></a><div class="site-author-name"><a href="/about">秩同道合</a></div><a class="site-name" href="/about/site.html">秩同道合的小站</a><sub class="site-subtitle">寻找志趣相投的伙伴！</sub><div class="site-desciption">我和你，以及我们的秩相同所以我们才等价！</div></div><nav class="site-state"><a class="site-state-item hty-icon-button icon-home" href="/" title="首页"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-home-4-line"></use></svg></span></a><div class="site-state-item site-state-posts"><a href="/archives" title="归档"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-archive-line"></use></svg></span><span class="site-state-item-count">29</span></a></div><div class="site-state-item site-state-categories"><a href="/categories" title="分类"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-2-line"></use></svg></span><span class="site-state-item-count">2</span></a></div><div class="site-state-item site-state-tags"><a href="/tags" title="标签"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="site-state-item-count">5</span></a></div><a class="site-state-item hty-icon-button" href="https://github.com/AlexZou14" target="_blank" rel="noopener" title="reward.comment"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-hand-coin-line"></use></svg></span></a></nav><hr style="margin-bottom:0.5rem"><div class="links-of-author"><a class="links-of-author-item hty-icon-button" rel="noopener" href="/atom.xml" title="RSS" target="_blank" style="color:orange"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-rss-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://github.com/AlexZou14" title="GitHub" target="_blank" style="color:#181717"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-github-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="mailto:1120375574@qq.com" title="E-Mail" target="_blank" style="color:#8E71C1"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-mail-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://space.bilibili.com/19164044" title="哔哩哔哩" target="_blank" style="color:#FF8EB3"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-bilibili-line"></use></svg></a></div><hr style="margin:0.5rem 1rem"><div class="links"><a class="links-item hty-icon-button" href="http://sotavision.cn" target="_blank" rel="noopener" title="工作组" style="color:#000000"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-send-plane-2-line"></use></svg></a></div></div><script defer src="/js/sidebar.js"></script><div class="sidebar-panel sidebar-panel-active" id="post-toc-wrap"><div class="post-toc"><div class="post-toc-progress"><div class="progress-bar"></div><div class="progress-info"><span class="progress-notice">您已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span></div></div><div class="post-toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#Abstract"><span class="toc-number">1.</span> <span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Introduction"><span class="toc-number">2.</span> <span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Related-work"><span class="toc-number">3.</span> <span class="toc-text">Related work</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#SISR-dataset"><span class="toc-number">3.1.</span> <span class="toc-text">SISR dataset</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Kernel-prediction-network"><span class="toc-number">3.2.</span> <span class="toc-text">Kernel prediction network</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Real-world-SISR-Dataset"><span class="toc-number">4.</span> <span class="toc-text">Real-world SISR Dataset</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Image-formation-by-thin-lens"><span class="toc-number">4.1.</span> <span class="toc-text">Image formation by thin lens</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Data-collection"><span class="toc-number">4.2.</span> <span class="toc-text">Data collection</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Image-pair-registration"><span class="toc-number">4.3.</span> <span class="toc-text">Image pair registration</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Laplacian-Pyramid-based-Kernel-Prediction-Network"><span class="toc-number">5.</span> <span class="toc-text">Laplacian Pyramid based Kernel Prediction Network</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Experiment"><span class="toc-number">6.</span> <span class="toc-text">Experiment</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Experiments-Details"><span class="toc-number">6.1.</span> <span class="toc-text">Experiments Details</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#SISR-models-trained-on-RealSR-dataset"><span class="toc-number">6.2.</span> <span class="toc-text">SISR models trained on RealSR dataset</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Comparisons-with-state-of-the-arts"><span class="toc-number">6.3.</span> <span class="toc-text">Comparisons with state-of-the-arts</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Conclusions"><span class="toc-number">7.</span> <span class="toc-text">Conclusions</span></a></li></ol></div></div></div></aside><main class="sidebar-translate" id="content"><div id="post"><article class="post-block" itemscope itemtype="http://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://alexzou14.github.io/2020/04/11/RealSR/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="秩同道合"><meta itemprop="description" content="Toward Real-World Single Image Super-Resolution:A New Benchmark and A New Model论文阅读笔记"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="秩同道合的小站"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">Toward Real-World Single Image Super-Resolution:A New Benchmark and A New Model论文阅读笔记</h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-calendar-line"></use></svg></span> <time title="创建时间：2020-04-11 18:34:11" itemprop="dateCreated datePublished" datetime="2020-04-11T18:34:11+08:00">2020-04-11</time></span><div class="post-count"><span class="post-symbolcount"><span class="post-meta-item-icon" title="本文字数"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-file-word-line"></use></svg></span> <span title="本文字数">5.7k</span><span class="post-meta-divider">-</span><span class="post-meta-item-icon" title="阅读时长"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-timer-line"></use></svg></span> <span title="阅读时长">11 分钟</span></span></div><span class="leancloud_visitors" id="/2020/04/11/RealSR/" data-flag-title="Toward Real-World Single Image Super-Resolution:A New Benchmark and A New Model论文阅读笔记"><span class="post-meta-item-icon" title="阅读次数"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-eye-line"></use></svg> <span class="leancloud-visitors-count"></span></span></span><div class="post-classify"><span class="post-category"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-line"></use></svg></span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a class="category" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="text">论文笔记</span></a></span></span><span class="post-tag"><span class="post-meta-divider">-</span><a class="tag" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">深度学习</span></a><a class="tag" href="/tags/%E7%AC%94%E8%AE%B0/"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">笔记</span></a><a class="tag" href="/tags/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87/"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">超分辨率</span></a></span></div></div></header><section class="post-body" itemprop="articleBody"><div class="post-content post-markdown"><h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>目前大多数基于学习的单图像超分辨率算法（Single Image Super Resolution,SISR）大多是基于模拟数据集（例如：对高分辨率图像（HR）进行Bicubic 降采样，或者加入高斯白噪声）。然而，真实低分辨率图像（LR）的降质过程往往是非常复杂而且不可知，因此在模拟数据集上训练的 SISR 算法在真实场景下往往效果不佳。<br>本文介绍了自己的数据集来更真实的还原现实世界的场景，提出了一个基于拉普拉斯的核预测网络。</p>
<hr>
<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>作者在这部分先说明了单一图像超分问题的不定性。现在的大多数方法都用模拟数据集来进行训练，所以现在大部分方法应用在现实场景中收到的效果不是特别好。作者通过调节焦距，在进行图像配对获得一组现实场景中的数据集。作者同时提出了一种Lap-KPN网络在现实场景中取得了比较好的结果。<br>本文主要贡献有：</p>
<ul>
<li><p>该论文提出了一个新的 Benchmark 数据集 RealSR dataset，它包含同场景下成对的 LR-HR 数据集，由变焦数码进行拍摄经过后期处理得到</p>
</li>
<li><p>由于真实图像降质核在数据集中并非完全一致，因此该论文提出了一个新的超分辨率算法LP-KPN：基于拉普拉斯金字塔的核预测网络。它能够有效地学习 per-pixel kernel（像素卷积核） 用于高分辨率图像的重建。</p>
</li>
</ul>
<hr>
<h3 id="Related-work"><a href="#Related-work" class="headerlink" title="Related work"></a>Related work</h3><h4 id="SISR-dataset"><a href="#SISR-dataset" class="headerlink" title="SISR dataset"></a>SISR dataset</h4><p>比较了当时使用比较广泛的数据集，如Set5、Set14、BSD300、Urban100、DIV2K等数据集。当下大多数网络训练过程中的LR图像都是通过对高分辨率图像（HR）进行Bicubic 降采样，或者加入高斯白噪声得到的。然后这些SISR模型在真实场景上恢复出来的HR图像比较差。</p>
<h4 id="Kernel-prediction-network"><a href="#Kernel-prediction-network" class="headerlink" title="Kernel prediction network"></a>Kernel prediction network</h4><p>作者介绍了KPN网络一开始是用来去噪的一个网络，由于现实场景下的低分辨率图像的模糊核是多样的，作者运用了相似的思想来恢复低分辨率图像。</p>
<hr>
<h3 id="Real-world-SISR-Dataset"><a href="#Real-world-SISR-Dataset" class="headerlink" title="Real-world SISR Dataset"></a>Real-world SISR Dataset</h3><h4 id="Image-formation-by-thin-lens"><a href="#Image-formation-by-thin-lens" class="headerlink" title="Image formation by thin lens"></a>Image formation by thin lens</h4><p>图像在相机生成的光学过程如下：<br><img src="http://sotavision.cn/showdoc/server/../Public/Uploads/2020-02-19/5e4d373365283.png" alt="" loading="lazy"><br>所以光学成像的表达式为：\({\dfrac{1}{f}}={\dfrac{1}{u}}+{\dfrac{1}{v}}\)<br>所以放大倍数可以表达为：\(M={\dfrac{h_2}{h_1}}={\dfrac{v}{u}}\)<br>所以当\(u \gg f\)时我们可以得到：\( h_2={\dfrac{f}{u-f}}\approx{\dfrac{f}{u}h} \)<br>所以可以通过调节焦距来获得到LR和HR图像</p>
<h4 id="Data-collection"><a href="#Data-collection" class="headerlink" title="Data collection"></a>Data collection</h4><p>使用了以上的相机来获得到图像：<br><img src="http://sotavision.cn/showdoc/server/../Public/Uploads/2020-02-19/5e4d3a520c86d.png" alt="" loading="lazy"></p>
<h4 id="Image-pair-registration"><a href="#Image-pair-registration" class="headerlink" title="Image pair registration"></a>Image pair registration</h4><p><img src="http://sotavision.cn/showdoc/server/../Public/Uploads/2020-02-19/5e4d3a84a9083.png" alt="" loading="lazy"><br>作者通过以上的对齐方式将获得到的图像整理成LR-HR的图像对制作成一个现实世界的训练集。</p>
<h3 id="Laplacian-Pyramid-based-Kernel-Prediction-Network"><a href="#Laplacian-Pyramid-based-Kernel-Prediction-Network" class="headerlink" title="Laplacian Pyramid based Kernel Prediction Network"></a>Laplacian Pyramid based Kernel Prediction Network</h3><p><img src="http://sotavision.cn/showdoc/server/../Public/Uploads/2020-02-19/5e4d3b89284c2.png" alt="" loading="lazy"><br>从图 1 看，网络一共分为2个部分：1.Backbone骨干网络，用于特征提取； 2.Per-pixel kernels at different level，处理不同拉普拉斯层级的解构图像，共有3层。对于每一个层，层级中的卷积对 Backbone 输出特征进行不同尺度缩放，然后提取特征输出 per-pixel kernel 特征矩阵，维度大小为\( H\times W\times (k\times k)\),其中\((k\times k)\)输出的卷积核尺寸。然后与对应的拉普拉斯金字塔解构图像进行如下的内积矩阵操作：<br>\[ I_H^P(i,j)=\left \langle {K(i,j),V(I_L^A(i,j))} \right \rangle \]<br>其中\( K(i,j) \)为per-pixel kernel 特征矩阵中\((i,j)\)位置的卷积核，\(V(I_L^A(i,j))\)为输入解构图像中，以\((i,j)\)位置的点位中心,\(k\times k\)大小的邻域。对于输入的每一个像素点，都有对应的卷积核单独对其邻域内的特征进行处理，所以 LP-KPN能够较好地应用于图像去噪，去模糊、超分辨率等任务，且效果较好。<br>LP-KPN 还利用 shuffle downsampling 和 shuffle upsampling，实现卷积特征空间分辨率上采样和下采样，其原理与 ESPCN 一致。在网络最前端进行4倍下采样，有效缓解了 输入图像尺寸与目标图像一致 而导致的计算消耗大的问题。 LP-KPN 输入图像为灰度图像，通过 shuffle downsampling 操作后，相当于将图像降采样成多张低分辨的灰度图像。</p>
<hr>
<h3 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h3><h4 id="Experiments-Details"><a href="#Experiments-Details" class="headerlink" title="Experiments Details"></a>Experiments Details</h4><p>具体实验细节可以参考：<a href="https://github.com/csjcai/RealSR" target="_blank" rel="noopener">https://github.com/csjcai/RealSR</a></p>
<h4 id="SISR-models-trained-on-RealSR-dataset"><a href="#SISR-models-trained-on-RealSR-dataset" class="headerlink" title="SISR models trained on RealSR dataset"></a>SISR models trained on RealSR dataset</h4><p>论文对比了不同的 SISR 模型在不同的数据集上进行训练，最终在真实图像测试集上进行测试的结果。可以看到在 RealSR 数据集上，相同模型能够生成视觉效果更好的图像，图像中的伪影和噪声更少，且边缘纹理更清晰。这说明了RealSR 数据集的有效性。<br><img src="http://sotavision.cn/showdoc/server/../Public/Uploads/2020-02-19/5e4d410bc9e0d.png" alt="" loading="lazy"></p>
<h4 id="Comparisons-with-state-of-the-arts"><a href="#Comparisons-with-state-of-the-arts" class="headerlink" title="Comparisons with state-of-the-arts"></a>Comparisons with state-of-the-arts</h4><p>论文对 LP-KPN方法的有效性进行了验证，LP-KPN 可以取得比 RCAN 相近的性能表现。<br><img src="http://sotavision.cn/showdoc/server/../Public/Uploads/2020-02-19/5e4d415614fdd.png" alt="" loading="lazy"></p>
<hr>
<h3 id="Conclusions"><a href="#Conclusions" class="headerlink" title="Conclusions"></a>Conclusions</h3><ul>
<li><p>该论文提出了一个新的 Benchmark 数据集 RealSR dataset，它包含同场景下成对的 LR-HR 数据集，由变焦数码进行拍摄经过后期处理得到</p>
</li>
<li><p>由于真实图像降质核在数据集中并非完全一致，因此该论文提出了一个新的超分辨率算法LP-KPN：基于拉普拉斯金字塔的核预测网络。它能够有效地学习 per-pixel kernel（像素卷积核） 用于高分辨率图像的重建。</p>
</li>
</ul>
</div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>秩同道合</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="http://alexzou14.github.io/2020/04/11/RealSR/" title="Toward Real-World Single Image Super-Resolution:A New Benchmark and A New Model论文阅读笔记">http://alexzou14.github.io/2020/04/11/RealSR/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>本博客所有文章除特别声明外，均默认采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0 "><svg class="icon"><use xlink:href="#icon-creative-commons-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-by-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-nc-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-sa-line"></use></svg></a> 许可协议。</li></ul></section></article><div class="post-nav"><div class="post-nav-item"><a class="post-nav-prev" href="/2020/04/23/RBPN/" rel="prev" title="Recurrent Back-Projection Network for Video Super-Resolution论文阅读笔记"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-left-s-line"></use></svg><span class="post-nav-text">Recurrent Back-Projection Network for Video Super-Resolution论文阅读笔记</span></a></div><div class="post-nav-item"><a class="post-nav-next" href="/2020/04/11/SRGAN/" rel="next" title="Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network论文阅读笔记"><span class="post-nav-text">Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network论文阅读笔记</span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-right-s-line"></use></svg></a></div></div><div id="comment"><div class="comment-tooltip text-center"><span>若您无 GitHub 账号，可直接在下方匿名评论。</span><br><span>若您想及时得到回复提醒，建议跳转 GitHub Issues 评论。</span><br><span>若没有本文 Issue，您可以使用 Comment 模版新建。</span><br><a class="hty-button hty-button--raised" id="github-issues" href="https://github.com/AlexZou14/alexzou14.github.io/issues?q=is:issue+Toward Real-World Single Image Super-Resolution:A New Benchmark and A New Model论文阅读笔记" target="_blank" rel="noopener">GitHub Issues</a></div><div class="comment-container" id="valine-container"></div></div><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.css"><script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script></div></main><footer class="sidebar-translate" id="footer"><div class="copyright"><span>&copy; 2019 – 2021 </span><span class="with-love" id="animate"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-cloud-line"></use></svg></span><span class="author"> 秩同道合</span></div><div class="powered"><span>由 <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a> 驱动 v4.2.0</span><span class="footer-separator">|</span><span>主题 - <a rel="noopener" href="https://github.com/YunYouJun/hexo-theme-yun" target="_blank"><span>Yun</span></a> v0.3.1</span></div><script defer src="https://cdn.jsdelivr.net/npm/valine@latest/dist/Valine.min.js"></script><script>function initValine() {
  new Valine(CONFIG.valine);
}
document.addEventListener("DOMContentLoaded", function() {
  initValine();
});</script></footer><a class="hty-icon-button" id="goUp" aria-label="back-to-top" href="#"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-up-s-line"></use></svg></a></div><script defer src="/js/utils.js"></script><script defer src="/js/hexo-theme-yun.js"></script><script src="https://cdn.jsdelivr.net/npm/live2d-widget@^3.1.3/lib/L2Dwidget.min.js"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"https://cdn.jsdelivr.net/npm/live2d-widget-model-hijiki@1.0.5/assets/hijiki.model.json"},"display":{"position":"right","width":200,"height":400},"mobile":{"show":true},"react":{"opacity":0.8},"dialog":{"enable":true,"hitokoto":true},"log":false});</script></body></html>