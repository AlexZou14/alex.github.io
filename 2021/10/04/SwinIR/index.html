<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="description" content="ICCVW2021 SwinIR:ETH结合Swin Transformer提出SOTA复原方案"><meta name="keywords" content="深度学习,笔记,超分辨率"><meta name="author" content="秩同道合"><meta name="copyright" content="秩同道合"><meta name="theme-color" content="#0078E7"><title>ICCVW2021 SwinIR:ETH结合Swin Transformer提出SOTA复原方案 | 秩同道合的小站</title><link rel="shortcut icon" href="https://cdn.jsdelivr.net/gh/AlexZou14/CDN/img/favicon.ico"><link rel="preload" href="/css/hexo-theme-yun.css" as="style"><link rel="preload" href="/js/utils.js" as="script"><link rel="preload" href="/js/hexo-theme-yun.js" as="script"><link rel="prefetch" href="/js/sidebar.js" as="script"><link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin><link rel="stylesheet" href="/css/hexo-theme-yun.css"><link rel="alternate" href="/atom.xml" title="秩同道合的小站"><script id="yun-config">
    let Yun = window.Yun || {};
    let CONFIG = {"root":"/","title":"秩同道合的小站","version":"0.3.1","anonymous_image":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/avatar/none.jpg","say":{"api":"https://v1.hitokoto.cn","hitokoto":true},"valine":{"el":"#valine-container","verify":false,"notify":false,"appId":"eCgP91hRSX8OtvCIR4MgLfcl-gzGzoHsz","appKey":"N5gVT8kUx5O0wMvc47SU040Y","serverURLs":null,"placeholder":"大佬求指教&nbsp_(:з」∠)_ （填写邮箱可以收到回复通知～）","avatar":null,"meta":["nick","mail","link"],"pageSize":10,"lang":"zh-cn","visitor":true},"fireworks":{"colors":["102, 167, 221","62, 131, 225","33, 78, 194"]}};
  </script><script src="//at.alicdn.com/t/font_1140697_pa6cswvjpq.js" async></script><meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="秩同道合的小站" type="application/atom+xml">
</head><body><script defer src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script defer src="/js/ui/fireworks.js"></script><canvas class="fireworks"></canvas><div class="container"><a class="sidebar-toggle sidebar-toggle-fixed hty-icon-button"><div class="hamburger hamburger--spin" type="button"><span class="hamburger-box"><span class="hamburger-inner"></span></span></div></a><aside class="sidebar"><ul class="sidebar-nav"><li class="sidebar-nav-item sidebar-nav-toc sidebar-nav-active hty-icon-button" data-target="post-toc-wrap" title="文章目录"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-list-ordered"></use></svg></li><li class="sidebar-nav-item sidebar-nav-overview hty-icon-button" data-target="site-overview-wrap" title="站点概览"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-passport-line"></use></svg></li></ul><div class="sidebar-panel" id="site-overview-wrap"><div class="site-info fix-top"><a class="site-author-avatar" href="/about" title="秩同道合"><img loading="lazy" src="https://cdn.jsdelivr.net/gh/AlexZou14/CDN/img/touxiang.jpg" alt="秩同道合"></a><div class="site-author-name"><a href="/about">秩同道合</a></div><a class="site-name" href="/about/site.html">秩同道合的小站</a><sub class="site-subtitle">寻找志趣相投的伙伴！</sub><div class="site-desciption">我和你，以及我们的秩相同所以我们才等价！</div></div><nav class="site-state"><a class="site-state-item hty-icon-button icon-home" href="/" title="首页"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-home-4-line"></use></svg></span></a><div class="site-state-item site-state-posts"><a href="/archives" title="归档"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-archive-line"></use></svg></span><span class="site-state-item-count">30</span></a></div><div class="site-state-item site-state-categories"><a href="/categories" title="分类"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-2-line"></use></svg></span><span class="site-state-item-count">2</span></a></div><div class="site-state-item site-state-tags"><a href="/tags" title="标签"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="site-state-item-count">5</span></a></div><a class="site-state-item hty-icon-button" href="https://github.com/AlexZou14" target="_blank" rel="noopener" title="reward.comment"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-hand-coin-line"></use></svg></span></a></nav><hr style="margin-bottom:0.5rem"><div class="links-of-author"><a class="links-of-author-item hty-icon-button" rel="noopener" href="/atom.xml" title="RSS" target="_blank" style="color:orange"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-rss-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://github.com/AlexZou14" title="GitHub" target="_blank" style="color:#181717"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-github-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="mailto:1120375574@qq.com" title="E-Mail" target="_blank" style="color:#8E71C1"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-mail-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://space.bilibili.com/19164044" title="哔哩哔哩" target="_blank" style="color:#FF8EB3"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-bilibili-line"></use></svg></a></div><hr style="margin:0.5rem 1rem"><div class="links"><a class="links-item hty-icon-button" href="http://sotavision.cn" target="_blank" rel="noopener" title="工作组" style="color:#000000"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-send-plane-2-line"></use></svg></a></div></div><script defer src="/js/sidebar.js"></script><div class="sidebar-panel sidebar-panel-active" id="post-toc-wrap"><div class="post-toc"><div class="post-toc-progress"><div class="progress-bar"></div><div class="progress-info"><span class="progress-notice">您已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span></div></div><div class="post-toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#Abstract"><span class="toc-number">1.</span> <span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Method"><span class="toc-number">2.</span> <span class="toc-text">Method</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#网络结构"><span class="toc-number">2.1.</span> <span class="toc-text">网络结构</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#浅层特征提取和深层特征提取模块"><span class="toc-number">2.1.1.</span> <span class="toc-text">浅层特征提取和深层特征提取模块</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#图像重建模块"><span class="toc-number">2.1.2.</span> <span class="toc-text">图像重建模块</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#损失函数"><span class="toc-number">2.1.3.</span> <span class="toc-text">损失函数</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#残差Swin-Transformer模块"><span class="toc-number">2.2.</span> <span class="toc-text">残差Swin Transformer模块</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Swin-Transformer层"><span class="toc-number">2.3.</span> <span class="toc-text">Swin Transformer层</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Experiments"><span class="toc-number">3.</span> <span class="toc-text">Experiments</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#主要结果"><span class="toc-number">3.1.</span> <span class="toc-text">主要结果</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#消融实验"><span class="toc-number">3.2.</span> <span class="toc-text">消融实验</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Conclusion"><span class="toc-number">4.</span> <span class="toc-text">Conclusion</span></a></li></ol></div></div></div></aside><main class="sidebar-translate" id="content"><div id="post"><article class="post-block" itemscope itemtype="http://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://alexzou14.github.io/2021/10/04/SwinIR/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="秩同道合"><meta itemprop="description" content="ICCVW2021 SwinIR:ETH结合Swin Transformer提出SOTA复原方案"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="秩同道合的小站"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">ICCVW2021 SwinIR:ETH结合Swin Transformer提出SOTA复原方案</h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-calendar-line"></use></svg></span> <time title="创建时间：2021-10-04 20:26:49" itemprop="dateCreated datePublished" datetime="2021-10-04T20:26:49+08:00">2021-10-04</time></span><div class="post-count"><span class="post-symbolcount"><span class="post-meta-item-icon" title="本文字数"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-file-word-line"></use></svg></span> <span title="本文字数">7.8k</span><span class="post-meta-divider">-</span><span class="post-meta-item-icon" title="阅读时长"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-timer-line"></use></svg></span> <span title="阅读时长">16 分钟</span></span></div><span class="leancloud_visitors" id="/2021/10/04/SwinIR/" data-flag-title="ICCVW2021 SwinIR:ETH结合Swin Transformer提出SOTA复原方案"><span class="post-meta-item-icon" title="阅读次数"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-eye-line"></use></svg> <span class="leancloud-visitors-count"></span></span></span><div class="post-classify"><span class="post-category"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-line"></use></svg></span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a class="category" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="text">论文笔记</span></a></span></span><span class="post-tag"><span class="post-meta-divider">-</span><a class="tag" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">深度学习</span></a><a class="tag" href="/tags/%E7%AC%94%E8%AE%B0/"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">笔记</span></a><a class="tag" href="/tags/%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87/"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">超分辨率</span></a></span></div></div></header><section class="post-body" itemprop="articleBody"><div class="post-content post-markdown"><h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>目前大多数优秀的图像复原方案往往采用CNN，很少有人将Transfromer的方案用到这类低级视觉任务中进行尝试。在本文中，作者就基于Swin Transformer提出了一种性能卓越的baseline模型SwinIR用于图像复原。SwinIR由三部分组成：浅层特征提取、深层特征提取和高质量图像重建。具体地说，深度特征提取模块由几个Residual Swin Transformer Blocks（RSTB）组成，每个块都有几个Swin Transformer层和一个残差连接构成。<br>与CNN方法相比，SwinIR有以下几点优势：</p>
<ul>
<li>图像内容和注意权重之间的交互作用，可以解释为空间变化的卷积。</li>
<li>RSTB中的滑动窗口机制可以进行长距离依赖建模</li>
<li>SwinIR可以用更少的参数获得更优异的性能</li>
</ul>
<img src="https://cdn.nlark.com/yuque/0/2021/png/22543740/1633336192573-c1e0a1cd-f4c3-4295-ae4a-349dce511991.png?x-oss-process=image%2Fresize%2Cw_1231%2Climit_0" referrerpolicy="no-referrer" loading="lazy">

<h3 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h3><h4 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h4><img src="https://cdn.nlark.com/yuque/0/2021/png/22543740/1633337893525-7a89199d-daa6-4dff-bd12-18ddd6937067.png?x-oss-process=image%2Fresize%2Cw_1504%2Climit_0" referrerpolicy="no-referrer" loading="lazy">

<p>如图2所示，SwinIR由三个模块组成：浅特征提取、深特征提取和高质量（HQ）图像重建模块。我们对所有恢复任务使用相同的特征提取模块，但对不同的任务使用不同的重建模块。</p>
<h5 id="浅层特征提取和深层特征提取模块"><a href="#浅层特征提取和深层特征提取模块" class="headerlink" title="浅层特征提取和深层特征提取模块"></a>浅层特征提取和深层特征提取模块</h5><p>假设低质量图像为\( I_{LQ}\in R^{H\times W\times C_{in}} \)，作者采用了\( 3\times 3 \)的卷积来提取浅层特征\(F_0\)，可以表示为：</p>
<div>
    \[ F_0 = H_{SF}(L_{LQ}) \]
</div>

<p>然后，利用Swin Transformer来进行深层特征提取：</p>
<div>
    \[ F_{DF}=H_{DF}(F_0) \]
</div>

<p>其中\( H_{SF} \)表示深层特征提取模块，这个模块由K个RSTB与一个\( 3\times 3 \)卷积构成。可以表示为以下公式：</p>
<div>
    \[ F_i = H_{RSTB_i}(F_{i-1}), i=1,2,\cdots,K \]
</div>
<div>
    \[ F_{DF}=H_{CONV}(F_K) \]
</div>

<h5 id="图像重建模块"><a href="#图像重建模块" class="headerlink" title="图像重建模块"></a>图像重建模块</h5><p>我们将提取得到的特征通过对应恢复任务的重建模块来得到最终的重建特征。可以表达如下：</p>
<div>
    \[ I_{RHQ} = H_{REC}(F_0+F_{DF}) \]
</div>

<h5 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h5><p>对于图像超分任务，作者采用了\( L_1 \)损失来进行优化：</p>
<div>
    \[ \mathcal{L} = ||I_{RHQ}-i_{HQ}||_1 \]
</div>
对于真实世界图像超分，我们采用损失、GAN损失以及感知损失的组合以提升视觉质量。对于图像降噪与JPEG压缩伪影任务，我们采用Charbonnier损失：
<div>
    \[ \mathcal{L} = \sqrt{||I_{RHQ}-i_{HQ}||^2+\epsilon^2} \]
</div>

<h4 id="残差Swin-Transformer模块"><a href="#残差Swin-Transformer模块" class="headerlink" title="残差Swin Transformer模块"></a>残差Swin Transformer模块</h4><img src="https://cdn.nlark.com/yuque/0/2021/png/22543740/1633338653750-64f29de0-4b13-477a-b34b-2573e6704aae.png" referrerpolicy="no-referrer" loading="lazy">

<p>上图a给出了RSTB的结构示意图，它包含多个STL、一个卷积以及残差连接。其公式可以表达为：</p>
<div>
    \[ F_{i,j}=H_{STL_{i,j}(F_{i,j-1})}, j=1,2,\cdots,L \]
</div>
然后，经过一个卷积层可以表示为：
<div>
    \[ F_{i, out} = H_{CONV_i}(F_{i,L})+F_{i,0} \]
</div>
这种设计思路有这样两个优势：
1) 尽管Transformer可以视作空间可变卷积的变种，但空间不变卷积有助于提升SwinIR的平移不变形；
2) 残差连接为不同模块到重建模块提供了等效连接，促进了不同层级特征的聚合。

<h4 id="Swin-Transformer层"><a href="#Swin-Transformer层" class="headerlink" title="Swin Transformer层"></a>Swin Transformer层</h4><p>Swin Transformer Layer(STL)基于原始Transformer中的标准多头自注意力演变而来，主要区别体现在于局部注意力与移位窗口机制。前述图b给出了STL结构示意图。假设输入尺寸为\( H\times W\times C \)，首先，将输入拆分为\( M\times M\)局部窗口并reshape为\( \frac{HW}{M^2}\times M^2\times C \)；然后，在每个窗口计算标准的自注意力。对于局部窗口特征\( X\in R^{M^2\times C} \)，query、key以及value计算如下：</p>
<div>
    \[ Attention(Q,K,V)=SoftMax(QK^T/\sqrt{d} +B)V \]
</div>

<p>其中B是代表相对位置编码的偏置项。接下来，作者采用包含两个全连接层与GELU激活函数进行特征变换。因此，整个过程可以描述为：</p>
<div>
    \[ X=MSA(LN(X))+X\\
    X=MLP(LN(X))+X \]
</div>

<p>对应的，窗口划分与窗口移位用于进行跨窗口信息交互。具体如下操作：</p>
<img src="https://cdn.nlark.com/yuque/0/2021/png/22543740/1633348341282-7bba4736-c2a1-41b7-b79b-d73accd9efc1.png?x-oss-process=image%2Fresize%2Cw_791%2Climit_0" referrerpolicy="no-referrer" loading="lazy">

<p>当窗口移位参数为0时，窗口裁切方式如Layer l所示，当窗口移位参数为x时，对应的平移x个像素点，如Layer l+1所示。但是，这个情况的窗口数目与前一个方式的窗口数目不同并且不是整切的，因此采用了cyclic shift来将左边上边的块补充到右下角再通过和第一种方式的裁剪得到相同的大小的窗口。</p>
<img src="https://cdn.nlark.com/yuque/0/2021/png/22543740/1633348377318-7692de38-2f33-43cb-94e2-7b66d1d0fb5e.png" referrerpolicy="no-referrer" loading="lazy">

<p>如图中，cyclic shift补充后的块，如果直接计算对应的attention，那么在对应的A, B, C所在的窗口计算的值会存在偏差，因此作者采用了Attention Mask来避免这个问题。<br>首先我们对 Shift Window 后的每个窗口都给上 index，并且做一个roll操作（window_size=2, shift_size=1）</p>
<img src="https://cdn.nlark.com/yuque/0/2021/png/22543740/1633349702516-66fbc43b-2066-4a21-94fc-3ee0dc3ff4b8.png" referrerpolicy="no-referrer" loading="lazy">

<p>我们希望在计算 Attention 的时候，让具有相同 index QK 进行计算，而忽略不同 index QK 计算结果。<br>最后正确的结果如下图所示：</p>
<img src="https://cdn.nlark.com/yuque/0/2021/png/22543740/1633349721502-390aa4d1-aaff-4fbd-9de2-0d66cb12e572.png" referrerpolicy="no-referrer" loading="lazy">

<p>而要想在原始四个窗口下得到正确的结果，我们就必须给 Attention 的结果加入一个 mask（如上图最右边所示）。</p>
<h3 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h3><h4 id="主要结果"><a href="#主要结果" class="headerlink" title="主要结果"></a>主要结果</h4><img src="https://cdn.nlark.com/yuque/0/2021/png/22543740/1633349834434-319be60e-ac89-46bd-91d5-a6409a04d38b.png?x-oss-process=image%2Fresize%2Cw_1500%2Climit_0" referrerpolicy="no-referrer" loading="lazy">

<p>上表给出了经典图像超分方面的性能对比，从中可以看到：</p>
<p>1) 当在DIV2K数据集上训练时，在五个基准数据集上，Swin取得了所有尺度最佳性能；PSNR增益最高甚至可达0.26dB。<br>2) 当在DIV2K+Flickr2K数据集上训练时，SwinIR的性能得到了进一步提升，超越了ImageNet数据集上训练的IPT;<br>3) 值得注意的是，SwinIR的参数量远小于IPT(11.8M vs 115.5M)，甚至比CNN方案的参数量（15.4~44.3M）还少；<br>4) 在推理速度方面，当输入为1024x1024时，RCAN、IPT以及SwinIR速度分别为0.2s、4.5s以及1.1s;</p>
<img src="https://cdn.nlark.com/yuque/0/2021/png/22543740/1633349874964-35423d03-9c63-4c01-b74c-e3c9b40cddae.png?x-oss-process=image%2Fresize%2Cw_1500%2Climit_0" referrerpolicy="no-referrer" loading="lazy">

<p>上图给出了SwinIR与其他超分方案的视觉效果对比，可以看到：SwinIR可以复原高频细节，具有更锐利而自然的边缘；相反，CNN方案生成结果往往具有模糊结果，甚至不正确的纹理。</p>
<h4 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h4><img src="https://cdn.nlark.com/yuque/0/2021/jpeg/22543740/1633349963328-fb13b6a5-ead1-40b0-948f-915016f916a7.jpeg" referrerpolicy="no-referrer" loading="lazy">

<p>上图a、b、c对通道数、模块数以及STL数进行消融分析对比，从中可以看到：</p>
<ul>
<li>PSNR指标与上述三个超参成正相关关系；</li>
<li>对于通道数而言，尽管通道数越多性能越好，但总参数成二次方关系增长。为平衡性能与模型大小，我们设置通道数180；</li>
<li>随RSTB模块数与STL数增加，模型性能很快饱和。我们将两者数量设为6以得到一个相对小的模型。<br>上图d、e、f对训练过程中的超参进行了消融分析对比，从中可以看到：</li>
<li>在不同patch尺寸下，SwinIR均取得了比RCAN更佳的性能，见上图d；</li>
<li>SwinIR性能会随训练数据量提升而提升且均比RCAN更优，见上图e；</li>
<li>SwinIR的收敛速度要比RCAN更快、更好，见上图f。</li>
</ul>
<img src="https://cdn.nlark.com/yuque/0/2021/png/22543740/1633351596946-13330eae-45df-4f46-bc24-2a56d27c7871.png?x-oss-process=image%2Fresize%2Cw_1504%2Climit_0" referrerpolicy="no-referrer" loading="lazy">
<img src="https://cdn.nlark.com/yuque/0/2021/png/22543740/1633351619115-0f6add4c-b2d8-4dca-a490-a45bcae7e72d.png?x-oss-process=image%2Fresize%2Cw_1504%2Climit_0" referrerpolicy="no-referrer" loading="lazy">
<img src="https://cdn.nlark.com/yuque/0/2021/png/22543740/1633351647743-c99e23f1-cdfe-4950-a5f0-eeab48df3f6c.png?x-oss-process=image%2Fresize%2Cw_1504%2Climit_0" referrerpolicy="no-referrer" loading="lazy">

<img src="https://cdn.nlark.com/yuque/0/2021/jpeg/22543740/1633349988671-8d667cc2-5d53-4614-a6f1-7b63b4f70e8f.jpeg" referrerpolicy="no-referrer" loading="lazy">

<p>上表对RSTB的各成分进行了消融对比，从中可以看到：</p>
<ul>
<li>残差连接非常重要，它可以提升的性能高达0.16dB；</li>
<li>卷积带来的性能增强非常有限，这是因为它不会像卷积一样提取局部近邻信息；</li>
<li>尽管采用三个卷积(减少中间卷积通道数)可以降低参数量，但性能同样轻微下降。</li>
</ul>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>本文主要是将Swin Transformer应用到图像恢复领域，Swin Transformer原本就是效果很卓越的模型，这篇论文进一步证明了这一点。这篇论文很好的启发我们将Transformer模型应用到低级视觉任务中，因此可以考虑结合UNet来进一步提升网络性能。</p>
</div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>秩同道合</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="http://alexzou14.github.io/2021/10/04/SwinIR/" title="ICCVW2021 SwinIR:ETH结合Swin Transformer提出SOTA复原方案">http://alexzou14.github.io/2021/10/04/SwinIR/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>本博客所有文章除特别声明外，均默认采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0 "><svg class="icon"><use xlink:href="#icon-creative-commons-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-by-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-nc-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-sa-line"></use></svg></a> 许可协议。</li></ul></section></article><div class="post-nav"><div class="post-nav-item"><a class="post-nav-prev" href="/2021/10/26/CRAN/" rel="prev" title="ICCV2021 注意力卷积新思路CRAN:上下文推理注意力图像超分辨率网络"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-left-s-line"></use></svg><span class="post-nav-text">ICCV2021 注意力卷积新思路CRAN:上下文推理注意力图像超分辨率网络</span></a></div><div class="post-nav-item"><a class="post-nav-next" href="/2021/09/28/mmediting/" rel="next" title="mmediting 使用手册"><span class="post-nav-text">mmediting 使用手册</span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-right-s-line"></use></svg></a></div></div><div id="comment"><div class="comment-tooltip text-center"><span>若您无 GitHub 账号，可直接在下方匿名评论。</span><br><span>若您想及时得到回复提醒，建议跳转 GitHub Issues 评论。</span><br><span>若没有本文 Issue，您可以使用 Comment 模版新建。</span><br><a class="hty-button hty-button--raised" id="github-issues" href="https://github.com/AlexZou14/alexzou14.github.io/issues?q=is:issue+ICCVW2021 SwinIR:ETH结合Swin Transformer提出SOTA复原方案" target="_blank" rel="noopener">GitHub Issues</a></div><div class="comment-container" id="valine-container"></div></div><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.css"><script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script></div></main><footer class="sidebar-translate" id="footer"><div class="copyright"><span>&copy; 2019 – 2021 </span><span class="with-love" id="animate"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-cloud-line"></use></svg></span><span class="author"> 秩同道合</span></div><div class="powered"><span>由 <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a> 驱动 v4.2.0</span><span class="footer-separator">|</span><span>主题 - <a rel="noopener" href="https://github.com/YunYouJun/hexo-theme-yun" target="_blank"><span>Yun</span></a> v0.3.1</span></div><script defer src="https://cdn.jsdelivr.net/npm/valine@latest/dist/Valine.min.js"></script><script>function initValine() {
  new Valine(CONFIG.valine);
}
document.addEventListener("DOMContentLoaded", function() {
  initValine();
});</script></footer><a class="hty-icon-button" id="goUp" aria-label="back-to-top" href="#"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-up-s-line"></use></svg></a></div><script defer src="/js/utils.js"></script><script defer src="/js/hexo-theme-yun.js"></script><script src="https://cdn.jsdelivr.net/npm/live2d-widget@^3.1.3/lib/L2Dwidget.min.js"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"https://cdn.jsdelivr.net/npm/live2d-widget-model-hijiki@1.0.5/assets/hijiki.model.json"},"display":{"position":"right","width":200,"height":400},"mobile":{"show":true},"react":{"opacity":0.8},"dialog":{"enable":true,"hitokoto":true},"log":false});</script></body></html>