<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="description" content="mmediting 使用手册"><meta name="keywords" content="pytorch,代码框架"><meta name="author" content="秩同道合"><meta name="copyright" content="秩同道合"><meta name="theme-color" content="#0078E7"><title>mmediting 使用手册 | 秩同道合的小站</title><link rel="shortcut icon" href="https://cdn.jsdelivr.net/gh/AlexZou14/CDN/img/favicon.ico"><link rel="preload" href="/css/hexo-theme-yun.css" as="style"><link rel="preload" href="/js/utils.js" as="script"><link rel="preload" href="/js/hexo-theme-yun.js" as="script"><link rel="prefetch" href="/js/sidebar.js" as="script"><link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin><link rel="stylesheet" href="/css/hexo-theme-yun.css"><link rel="alternate" href="/atom.xml" title="秩同道合的小站"><script id="yun-config">
    let Yun = window.Yun || {};
    let CONFIG = {"root":"/","title":"秩同道合的小站","version":"0.3.1","anonymous_image":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/avatar/none.jpg","say":{"api":"https://v1.hitokoto.cn","hitokoto":true},"valine":{"el":"#valine-container","verify":false,"notify":false,"appId":"eCgP91hRSX8OtvCIR4MgLfcl-gzGzoHsz","appKey":"N5gVT8kUx5O0wMvc47SU040Y","serverURLs":null,"placeholder":"大佬求指教&nbsp_(:з」∠)_ （填写邮箱可以收到回复通知～）","avatar":null,"meta":["nick","mail","link"],"pageSize":10,"lang":"zh-cn","visitor":true},"fireworks":{"colors":["102, 167, 221","62, 131, 225","33, 78, 194"]}};
  </script><script src="//at.alicdn.com/t/font_1140697_pa6cswvjpq.js" async></script><meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="秩同道合的小站" type="application/atom+xml">
</head><body><script defer src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script defer src="/js/ui/fireworks.js"></script><canvas class="fireworks"></canvas><div class="container"><a class="sidebar-toggle sidebar-toggle-fixed hty-icon-button"><div class="hamburger hamburger--spin" type="button"><span class="hamburger-box"><span class="hamburger-inner"></span></span></div></a><aside class="sidebar"><ul class="sidebar-nav"><li class="sidebar-nav-item sidebar-nav-toc sidebar-nav-active hty-icon-button" data-target="post-toc-wrap" title="文章目录"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-list-ordered"></use></svg></li><li class="sidebar-nav-item sidebar-nav-overview hty-icon-button" data-target="site-overview-wrap" title="站点概览"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-passport-line"></use></svg></li></ul><div class="sidebar-panel" id="site-overview-wrap"><div class="site-info fix-top"><a class="site-author-avatar" href="/about" title="秩同道合"><img loading="lazy" src="https://cdn.jsdelivr.net/gh/AlexZou14/CDN/img/touxiang.jpg" alt="秩同道合"></a><div class="site-author-name"><a href="/about">秩同道合</a></div><a class="site-name" href="/about/site.html">秩同道合的小站</a><sub class="site-subtitle">寻找志趣相投的伙伴！</sub><div class="site-desciption">我和你，以及我们的秩相同所以我们才等价！</div></div><nav class="site-state"><a class="site-state-item hty-icon-button icon-home" href="/" title="首页"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-home-4-line"></use></svg></span></a><div class="site-state-item site-state-posts"><a href="/archives" title="归档"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-archive-line"></use></svg></span><span class="site-state-item-count">28</span></a></div><div class="site-state-item site-state-categories"><a href="/categories" title="分类"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-2-line"></use></svg></span><span class="site-state-item-count">2</span></a></div><div class="site-state-item site-state-tags"><a href="/tags" title="标签"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="site-state-item-count">5</span></a></div><a class="site-state-item hty-icon-button" href="https://github.com/AlexZou14" target="_blank" rel="noopener" title="reward.comment"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-hand-coin-line"></use></svg></span></a></nav><hr style="margin-bottom:0.5rem"><div class="links-of-author"><a class="links-of-author-item hty-icon-button" rel="noopener" href="/atom.xml" title="RSS" target="_blank" style="color:orange"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-rss-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://github.com/AlexZou14" title="GitHub" target="_blank" style="color:#181717"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-github-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="mailto:1120375574@qq.com" title="E-Mail" target="_blank" style="color:#8E71C1"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-mail-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://space.bilibili.com/19164044" title="哔哩哔哩" target="_blank" style="color:#FF8EB3"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-bilibili-line"></use></svg></a></div><hr style="margin:0.5rem 1rem"><div class="links"><a class="links-item hty-icon-button" href="http://sotavision.cn" target="_blank" rel="noopener" title="工作组" style="color:#000000"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-send-plane-2-line"></use></svg></a></div></div><script defer src="/js/sidebar.js"></script><div class="sidebar-panel sidebar-panel-active" id="post-toc-wrap"><div class="post-toc"><div class="post-toc-progress"><div class="progress-bar"></div><div class="progress-info"><span class="progress-notice">您已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span></div></div><div class="post-toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#安装MMEditing"><span class="toc-number">1.</span> <span class="toc-text">安装MMEditing</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#需要安装的库"><span class="toc-number">1.1.</span> <span class="toc-text">需要安装的库</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#安装"><span class="toc-number">1.2.</span> <span class="toc-text">安装</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#使用MMEditing"><span class="toc-number">2.</span> <span class="toc-text">使用MMEditing</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#图像超分辨率数据集："><span class="toc-number">2.1.</span> <span class="toc-text">图像超分辨率数据集：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#训练模型"><span class="toc-number">2.2.</span> <span class="toc-text">训练模型</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#直接使用SRAnnotationDataset训练"><span class="toc-number">2.2.1.</span> <span class="toc-text">直接使用SRAnnotationDataset训练</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#使用LMDB环境进行训练"><span class="toc-number">2.2.2.</span> <span class="toc-text">使用LMDB环境进行训练</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#模型参数计算"><span class="toc-number">2.3.</span> <span class="toc-text">模型参数计算</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#模型构建"><span class="toc-number">3.</span> <span class="toc-text">模型构建</span></a></li></ol></div></div></div></aside><main class="sidebar-translate" id="content"><div id="post"><article class="post-block" itemscope itemtype="http://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://alexzou14.github.io/2021/09/28/mmediting/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="秩同道合"><meta itemprop="description" content="mmediting 使用手册"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="秩同道合的小站"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">mmediting 使用手册</h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-calendar-line"></use></svg></span> <time title="创建时间：2021-09-28 16:57:08" itemprop="dateCreated datePublished" datetime="2021-09-28T16:57:08+08:00">2021-09-28</time></span><div class="post-count"><span class="post-symbolcount"><span class="post-meta-item-icon" title="本文字数"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-file-word-line"></use></svg></span> <span title="本文字数">13k</span><span class="post-meta-divider">-</span><span class="post-meta-item-icon" title="阅读时长"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-timer-line"></use></svg></span> <span title="阅读时长">27 分钟</span></span></div><span class="leancloud_visitors" id="/2021/09/28/mmediting/" data-flag-title="mmediting 使用手册"><span class="post-meta-item-icon" title="阅读次数"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-eye-line"></use></svg> <span class="leancloud-visitors-count"></span></span></span><div class="post-classify"><span class="post-category"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-line"></use></svg></span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a class="category" href="/categories/%E7%BC%96%E7%A8%8B%E5%B7%A5%E5%85%B7/" itemprop="url" rel="index"><span itemprop="text">编程工具</span></a></span></span><span class="post-tag"><span class="post-meta-divider">-</span><a class="tag" href="/tags/pytorch/"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">pytorch</span></a><a class="tag" href="/tags/%E4%BB%A3%E7%A0%81%E6%A1%86%E6%9E%B6/"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">代码框架</span></a></span></div></div></header><section class="post-body" itemprop="articleBody"><div class="post-content post-markdown"><h3 id="安装MMEditing"><a href="#安装MMEditing" class="headerlink" title="安装MMEditing"></a>安装MMEditing</h3><h4 id="需要安装的库"><a href="#需要安装的库" class="headerlink" title="需要安装的库"></a>需要安装的库</h4><ul>
<li>pytorch 1.3 或者更高</li>
<li>CUDA9.0 及以上</li>
<li>mmcv</li>
<li>GCC4.9及以上</li>
<li>NCCL2及以上</li>
</ul>
<h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><p>创建一个conda的虚拟环境</p>
<pre><code>conda create -n open-mmlab python=3.7 -y
conda activate open-mmlab</code></pre><p>进入open-mmlab后安装对应的pytorch库</p>
<pre><code>对应不同的CUDA版本安装对应的pytorch，例如：
conda install pytorch cudatoolkit=10.1 torchvision -c pytorch
conda install pytorch=1.3.1 cudatoolkit=9.2 torchvision=0.4.2 -c pytorch</code></pre><p>将mmediting仓库下载到本地</p>
<pre><code>git clone http://github.com/open-mmlab/mmediting.git</code></pre><p>安装mmediting中需要的库文件</p>
<pre><code>cd mmediting
pip install -r requirements.txt</code></pre><p>其中这里安装mmcv-full可能会安装失败，所以我们可以通过以下方式将mmcv-full安装上(参考自<a href="https://github.com/open-mmlab/mmcv/blob/master/README.md)：" target="_blank" rel="noopener">https://github.com/open-mmlab/mmcv/blob/master/README.md)：</a></p>
<table>
<thead>
<tr>
<th>CUDA</th>
<th>torch1.7</th>
<th>torch1.6</th>
<th>torch1.5</th>
<th>torch1.4</th>
<th>torch1.3</th>
</tr>
</thead>
<tbody><tr>
<td>11.0</td>
<td><details><pre><code>pip install mmcv-full=={mmcv_version} -f <a href="https://download.openmmlab.com/mmcv/dist/cu110/torch1.7.0/index.html" target="_blank" rel="noopener">https://download.openmmlab.com/mmcv/dist/cu110/torch1.7.0/index.html</a></code></pre></details></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>10.2</td>
<td><details><pre><code>pip install mmcv-full=={mmcv_version} -f <a href="https://download.openmmlab.com/mmcv/dist/cu102/torch1.7.0/index.html" target="_blank" rel="noopener">https://download.openmmlab.com/mmcv/dist/cu102/torch1.7.0/index.html</a></code></pre></details></td>
<td><details><pre><code>pip install mmcv-full=={mmcv_version} -f <a href="https://download.openmmlab.com/mmcv/dist/cu102/torch1.6.0/index.html" target="_blank" rel="noopener">https://download.openmmlab.com/mmcv/dist/cu102/torch1.6.0/index.html</a></code></pre></details></td>
<td><details><pre><code>pip install mmcv-full=={mmcv_version} -f <a href="https://download.openmmlab.com/mmcv/dist/cu102/torch1.5.0/index.html" target="_blank" rel="noopener">https://download.openmmlab.com/mmcv/dist/cu102/torch1.5.0/index.html</a></code></pre></details></td>
<td></td>
<td></td>
</tr>
<tr>
<td>10.1</td>
<td><details><pre><code>pip install mmcv-full=={mmcv_version} -f <a href="https://download.openmmlab.com/mmcv/dist/cu101/torch1.7.0/index.html" target="_blank" rel="noopener">https://download.openmmlab.com/mmcv/dist/cu101/torch1.7.0/index.html</a></code></pre></details></td>
<td><details><pre><code>pip install mmcv-full=={mmcv_version} -f <a href="https://download.openmmlab.com/mmcv/dist/cu101/torch1.6.0/index.html" target="_blank" rel="noopener">https://download.openmmlab.com/mmcv/dist/cu101/torch1.6.0/index.html</a></code></pre></details></td>
<td><details><pre><code>pip install mmcv-full=={mmcv_version} -f <a href="https://download.openmmlab.com/mmcv/dist/cu101/torch1.5.0/index.html" target="_blank" rel="noopener">https://download.openmmlab.com/mmcv/dist/cu101/torch1.5.0/index.html</a></code></pre></details></td>
<td><details><pre><code>pip install mmcv-full=={mmcv_version} -f <a href="https://download.openmmlab.com/mmcv/dist/cu101/torch1.4.0/index.html" target="_blank" rel="noopener">https://download.openmmlab.com/mmcv/dist/cu101/torch1.4.0/index.html</a></code></pre></details></td>
<td><details><pre><code>pip install mmcv-full=={mmcv_version} -f <a href="https://download.openmmlab.com/mmcv/dist/cu101/torch1.3.0/index.html" target="_blank" rel="noopener">https://download.openmmlab.com/mmcv/dist/cu101/torch1.3.0/index.html</a></code></pre></details></td>
</tr>
<tr>
<td>9.2</td>
<td><details><pre><code>pip install mmcv-full=={mmcv_version} -f <a href="https://download.openmmlab.com/mmcv/dist/cu92/torch1.7.0/index.html" target="_blank" rel="noopener">https://download.openmmlab.com/mmcv/dist/cu92/torch1.7.0/index.html</a></code></pre></details></td>
<td><details><pre><code>pip install mmcv-full=={mmcv_version} -f <a href="https://download.openmmlab.com/mmcv/dist/cu92/torch1.6.0/index.html" target="_blank" rel="noopener">https://download.openmmlab.com/mmcv/dist/cu92/torch1.6.0/index.html</a></code></pre></details></td>
<td><details><pre><code>pip install mmcv-full=={mmcv_version} -f <a href="https://download.openmmlab.com/mmcv/dist/cu92/torch1.5.0/index.html" target="_blank" rel="noopener">https://download.openmmlab.com/mmcv/dist/cu92/torch1.5.0/index.html</a></code></pre></details></td>
<td><details><pre><code>pip install mmcv-full=={mmcv_version} -f <a href="https://download.openmmlab.com/mmcv/dist/cu92/torch1.4.0/index.html" target="_blank" rel="noopener">https://download.openmmlab.com/mmcv/dist/cu92/torch1.4.0/index.html</a></code></pre></details></td>
<td><details><pre><code>pip install mmcv-full=={mmcv_version} -f <a href="https://download.openmmlab.com/mmcv/dist/cu92/torch1.3.0/index.html" target="_blank" rel="noopener">https://download.openmmlab.com/mmcv/dist/cu92/torch1.3.0/index.html</a></code></pre></details></td>
</tr>
<tr>
<td>cpu</td>
<td><details><pre><code>pip install mmcv-full=={mmcv_version} -f <a href="https://download.openmmlab.com/mmcv/dist/cpu/torch1.7.0/index.html" target="_blank" rel="noopener">https://download.openmmlab.com/mmcv/dist/cpu/torch1.7.0/index.html</a></code></pre></details></td>
<td><details><pre><code>pip install mmcv-full=={mmcv_version} -f <a href="https://download.openmmlab.com/mmcv/dist/cpu/torch1.6.0/index.html" target="_blank" rel="noopener">https://download.openmmlab.com/mmcv/dist/cpu/torch1.6.0/index.html</a></code></pre></details></td>
<td><details><pre><code>pip install mmcv-full=={mmcv_version} -f <a href="https://download.openmmlab.com/mmcv/dist/cpu/torch1.5.0/index.html" target="_blank" rel="noopener">https://download.openmmlab.com/mmcv/dist/cpu/torch1.5.0/index.html</a></code></pre></details></td>
<td><details><pre><code>pip install mmcv-full=={mmcv_version} -f <a href="https://download.openmmlab.com/mmcv/dist/cpu/torch1.4.0/index.html" target="_blank" rel="noopener">https://download.openmmlab.com/mmcv/dist/cpu/torch1.4.0/index.html</a></code></pre></details></td>
<td><details><pre><code>pip install mmcv-full=={mmcv_version} -f <a href="https://download.openmmlab.com/mmcv/dist/cpu/torch1.3.0/index.htmll" target="_blank" rel="noopener">https://download.openmmlab.com/mmcv/dist/cpu/torch1.3.0/index.htmll</a></code></pre></details></td>
</tr>
</tbody></table>
<p>其中对应的{mmcv_version}我们可以替换成我们需要安装mmcv的版本，例如1.2.2版本，CUDA 11, pytorch 1.7.0，安装命令如下：</p>
<pre><code>pip install mmcv-full==1.2.2 -f https://download.openmmlab.com/mmcv/dist/cu110/torch1.7.0/index.html</code></pre><p>安装好mmcv-full后再进行后面的一条命令：</p>
<pre><code>pip install -v -e .</code></pre><hr>
<h3 id="使用MMEditing"><a href="#使用MMEditing" class="headerlink" title="使用MMEditing"></a>使用MMEditing</h3><h4 id="图像超分辨率数据集："><a href="#图像超分辨率数据集：" class="headerlink" title="图像超分辨率数据集："></a>图像超分辨率数据集：</h4><ul>
<li>Training dataset: <a href="https://data.vision.ee.ethz.ch/cvl/DIV2K/" target="_blank" rel="noopener" title="DIV2K dataset">DIV2K dataset</a></li>
<li>Validation dataset: Set5 and Set14.</li>
</ul>
<p>这里为了方便起见，我们按照以下文档给出的文件目录把数据集放入mmediting文件夹中的data文件夹中</p>
<pre><code>mmediting
├── mmedit
├── tools
├── configs
├── data
│   ├── DIV2K
│   │   ├── DIV2K_train_HR
│   │   ├── DIV2K_train_LR_bicubic
│   │   │   ├── X2
│   │   │   ├── X3
│   │   │   ├── X4
│   ├── val_set5
│   │   ├── Set5_bicLRx2
│   │   ├── Set5_bicLRx3
│   │   ├── Set5_bicLRx4
│   │   ├── Set5_mod12
│   ├── val_set14
│   │   ├── Set14_bicLRx2
│   │   ├── Set14_bicLRx3
│   │   ├── Set14_bicLRx4
│   │   ├── Set14_mod12
│   ├── ...  ————&gt;这里可以加入需要的数据集，格式如上</code></pre><p>注意这里每一个数据集中都应该包含2，3和4倍下采样的图片，不然会报错！！！要获得每个数据集中的不同倍数的图像，我们可以利用这个脚本来对HR图像进行处理得到：<br>脚本链接（参考mmsr得到）：<a href="http://sotavision.cn:8000/f/c34315c21f/?raw=1" target="_blank" rel="noopener" title="generate_mod_LR_bic.py">generate_mod_LR_bic.py</a>，通过修改里面对应的输入文件夹和输出文件夹就行:</p>
<pre><code>通过修改对应的dataset_path再运行就可以获取2，3，4倍图像
for i in [2,3,4]:
    generate_mod_LR_bic(up_scale=i, mod_scale=12, sourcedir={datasets_path})</code></pre><p>然后我们直接通过命令对训练集直接获取LMDB文件：</p>
<pre><code>python tools/preprocess_div2k_dataset.py --data-root ./data/DIV2K --make-lmdb</code></pre><p>这里会先对图像进行裁剪得到_sub文件夹然后再进行转换成lmdb文件，所以我们可以得到如下的文件夹：</p>
<pre><code>mmediting
├── mmedit
├── tools
├── configs
├── data
│   ├── DIV2K
│   │   ├── DIV2K_train_HR
│   │   ├── DIV2K_train_HR_sub
│   │   ├── DIV2K_train_HR_sub.lmdb
│   │   │   ├── data.mdb
│   │   │   ├── lock.mdb
│   │   │   ├── meta_info.txt
│   │   ├── DIV2K_train_LR_bicubic
│   │   │   ├── X2
│   │   │   ├── X3
│   │   │   ├── X4
│   │   │   ├── X2_sub
│   │   │   ├── X3_sub
│   │   │   ├── X4_sub
│   │   ├── DIV2K_train_LR_bicubic_X2_sub.lmdb
│   │   ├── DIV2K_train_LR_bicubic_X3_sub.lmdb
│   │   ├── DIV2K_train_LR_bicubic_X4_sub.lmdb
│   │   ├── ...</code></pre><p>这样就数据准备完毕了！！！</p>
<h4 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h4><h5 id="直接使用SRAnnotationDataset训练"><a href="#直接使用SRAnnotationDataset训练" class="headerlink" title="直接使用SRAnnotationDataset训练"></a>直接使用SRAnnotationDataset训练</h5><p>我们这里先用EDSRx2为例，我们先打开<code>config/resotrers/edsr/</code>文件夹中的<code>edsr_x2c64b16_g1_300k_div2k.py</code>，修改文件中的下面信息再保存：</p>
<pre><code>训练集数据位置保证是正确的
#train
lq_folder=&apos;data/DIV2K/DIV2K_train_LR_bicubic/X2_sub&apos;,
gt_folder=&apos;data/DIV2K/DIV2K_train_HR_sub&apos;,
ann_file=&apos;data/DIV2K/DIV2K_train_HR_sub.lmdb/meta_info.txt&apos; #这个文件就是上面处理为lmdb文件后得到的.txt文件
#val
lq_folder=&apos;./data/val_set5/Set5_bicLRx2&apos;,
gt_folder=&apos;./data/val_set5/Set5_mod12&apos;, #--&gt;这里可以替换成你要测试的数据集的文件夹
#test
lq_folder=&apos;./data/val_set5/Set5_bicLRx2&apos;,
gt_folder=&apos;./data/val_set5/Set5_mod12&apos;, #--&gt;这个数据集是最后训练结束测试的数据集
# learning policy
total_iters = 300000 #--&gt;这里调节训练的轮数
lr_config = dict(policy=&apos;Step&apos;, by_epoch=False, step=[200000], gamma=0.5) #--&gt;这里调节训练策略</code></pre><p>修改完成后就可以在open-mmlab环境下通过下面的命令行训练：</p>
<pre><code>cd mmediting
./tools/dist_train.sh {CONFIG_FILE} {GPU_NUM} [optional arguments] #——&gt;其中CONFIG_FILE是表示我们需要训练的配置文件，GPU_NUM是代表我们使用GPU数量</code></pre><p>后面的<code>[optional arguments]</code>是表示可以输入的参数，其中参数列表如下：</p>
<ul>
<li><code>--no-validate</code>: 添加这个参数，就是使得训练过程中没有valuation</li>
<li><code>--work-dir {WORK_DIR}</code>: 这里就可以指定训练出来的结果保存在哪个文件夹</li>
<li><code>--resume-from {CHECKPOINT_FILE}</code>: 这里是前面的训练的权重和优化器的状态都加到模型中</li>
</ul>
<p>然后，我们以EDSR为例，可以写为：</p>
<pre><code>./tools/dist_train.sh config/resotrers/edsr/edsr_x2c64b16_g1_300k_div2k.py 1 --work-dir EDSRx2 --resume-from xxxxxxxxx.pt</code></pre><h5 id="使用LMDB环境进行训练"><a href="#使用LMDB环境进行训练" class="headerlink" title="使用LMDB环境进行训练"></a>使用LMDB环境进行训练</h5><p>相应的打开<code>config/resotrers/edsr/</code>文件夹中<code>edsr_x2c64b16_g1_300k_div2k.py</code>，需要修改以下参数：</p>
<pre><code>1.找到train_dataset_type这个参数，我们修改为如下：
train_dataset_type = &apos;SRLmdbDataset&apos;
2.找到data对应的字典，修改train就行，如下：
 # train
samples_per_gpu=16,
workers_per_gpu=6,
drop_last=True,
train=dict(
    type=&apos;RepeatDataset&apos;,
    times=1000,
    dataset=dict(
        type=train_dataset_type,
        lq_folder=&apos;data/DIV2K/DIV2K_train_LR_bicubic_X2_sub.lmdb&apos;,--------&gt;这里修改成你得到.lmdb格式lq文件夹
        gt_folder=&apos;data/DIV2K/DIV2K_train_HR_sub.lmdb&apos;,--------&gt;这里修改成你得到.lmdb格式gt文件夹
        # ann_file=&apos;data/DIV2K/meta_info_DIV2K800sub_GT.txt&apos;,--------&gt;这里注释掉ann_file，因为SRLmdbDataset没有这个参数！
        pipeline=train_pipeline,
        scale=scale)),
3.找到train_pipeline，修改这个参数下面第一个字典和第二个字典参数，如下：
dict(
    type=&apos;LoadImageFromFile&apos;,
    io_backend=&apos;lmdb&apos;,
    key=&apos;lq&apos;,
    db_path=&apos;data/DIV2K/DIV2K_train_LR_bicubic_X2_sub.lmdb&apos;,
    flag=&apos;unchanged&apos;),
dict(
    type=&apos;LoadImageFromFile&apos;,
    io_backend=&apos;lmdb&apos;,
    key=&apos;gt&apos;,
    db_path=&apos;data/DIV2K/DIV2K_train_HR_sub.lmdb&apos;,
    flag=&apos;unchanged&apos;),</code></pre><h4 id="模型参数计算"><a href="#模型参数计算" class="headerlink" title="模型参数计算"></a>模型参数计算</h4><p>mmediting计算模型的参数和FLOPS用如下命令:</p>
<pre><code>python tools/get_flops.py {CONFIG_FILE} [--shape {INPUT_SHAPE}]</code></pre><p>例如：</p>
<pre><code>python tools/get_flops.py configs/resotorer/xxxxxxxxxxx.py --shape 40 40</code></pre><p>得到结果如下所示：</p>
<pre><code>==============================
Input shape: (3, 40, 40)
Flops: 4.07 GMac
Params: 1.52 M
==============================</code></pre><h3 id="模型构建"><a href="#模型构建" class="headerlink" title="模型构建"></a>模型构建</h3><p>我们将我们自己写好的模型加入进<code>mmediting/mmedit/models/backbones/sr_backbones</code>文件夹中, 对照EDSR中的格式改成相应<code>.py</code>文件，再在<code>__init__</code>文件中添加对应的模型。<br>如果要设计对应的loss函数，可以将写好的Loss文件加入<code>mmediting/mmedit/models/losses/</code>文件加中，对照其他文件改成相应的格式，再在<code>__init__</code>文件中添加对应的loss名称。</p>
</div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>秩同道合</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="http://alexzou14.github.io/2021/09/28/mmediting/" title="mmediting 使用手册">http://alexzou14.github.io/2021/09/28/mmediting/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>本博客所有文章除特别声明外，均默认采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0 "><svg class="icon"><use xlink:href="#icon-creative-commons-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-by-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-nc-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-sa-line"></use></svg></a> 许可协议。</li></ul></section></article><div class="post-nav"><div class="post-nav-item"></div><div class="post-nav-item"><a class="post-nav-next" href="/2021/09/28/MANet/" rel="next" title="ICCV2021 盲图像超分MANet:空间可变模糊核估计的互仿射网络"><span class="post-nav-text">ICCV2021 盲图像超分MANet:空间可变模糊核估计的互仿射网络</span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-right-s-line"></use></svg></a></div></div><div id="comment"><div class="comment-tooltip text-center"><span>若您无 GitHub 账号，可直接在下方匿名评论。</span><br><span>若您想及时得到回复提醒，建议跳转 GitHub Issues 评论。</span><br><span>若没有本文 Issue，您可以使用 Comment 模版新建。</span><br><a class="hty-button hty-button--raised" id="github-issues" href="https://github.com/AlexZou14/alexzou14.github.io/issues?q=is:issue+mmediting 使用手册" target="_blank" rel="noopener">GitHub Issues</a></div><div class="comment-container" id="valine-container"></div></div></div></main><footer class="sidebar-translate" id="footer"><div class="copyright"><span>&copy; 2019 – 2021 </span><span class="with-love" id="animate"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-cloud-line"></use></svg></span><span class="author"> 秩同道合</span></div><div class="powered"><span>由 <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a> 驱动 v4.2.0</span><span class="footer-separator">|</span><span>主题 - <a rel="noopener" href="https://github.com/YunYouJun/hexo-theme-yun" target="_blank"><span>Yun</span></a> v0.3.1</span></div><script defer src="https://cdn.jsdelivr.net/npm/valine@latest/dist/Valine.min.js"></script><script>function initValine() {
  new Valine(CONFIG.valine);
}
document.addEventListener("DOMContentLoaded", function() {
  initValine();
});</script></footer><a class="hty-icon-button" id="goUp" aria-label="back-to-top" href="#"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-up-s-line"></use></svg></a></div><script defer src="/js/utils.js"></script><script defer src="/js/hexo-theme-yun.js"></script><script src="https://cdn.jsdelivr.net/npm/live2d-widget@^3.1.3/lib/L2Dwidget.min.js"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"https://cdn.jsdelivr.net/npm/live2d-widget-model-hijiki@1.0.5/assets/hijiki.model.json"},"display":{"position":"right","width":200,"height":400},"mobile":{"show":true},"react":{"opacity":0.8},"dialog":{"enable":true,"hitokoto":true},"log":false});</script></body></html>